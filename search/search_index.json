{"config":{"lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Yelmo Welcome to Yelmo , an easy to use continental ice sheet model. Yelmo is a 3D ice-sheet-shelf model solving for the coupled dynamics and thermodynamics of the ice sheet system. Yelmo can be used for idealized simulations, stand-alone ice sheet simulations and fully coupled ice-sheet and climate simulations. Yelmo has been designed to operate as a stand-alone model or to be easily plugged in as a module in another program. The key to its flexibility is that no variables are defined globally and parameters are defined according to the domain being modeled. In this way, all variables and calculations are store in an object that entirely represents the model domain. The physics and design of Yelmo are described in the following article: Robinson, A., Alvarez-Solas, J., Montoya, M., Goelzer, H., Greve, R., and Ritz, C.: Description and validation of the ice-sheet model Yelmo (version 1.0), Geosci. Model Dev., 13, 2805\u20132823, https://doi.org/10.5194/gmd-13-2805-2020 , 2020. The Yelmo code repository can be found here: https://github.com/palma-ice/yelmo General model structure - classes and usage yelmo_class The Yelmo class defines all data related to a model domain, such as Greenland or Antarctica. As seen below in the yelmo_class defintion, the 'class' is simply a user-defined Fortran type that contains additional types representing various parameters, variables or sets of module variables. type yelmo_class type(yelmo_param_class) :: par ! General domain parameters type(ygrid_class) :: grd ! Grid definition type(ytopo_class) :: tpo ! Topography variables type(ydyn_class) :: dyn ! Dynamics variables type(ymat_class) :: mat ! Material variables type(ytherm_class) :: thrm ! Thermodynamics variables type(ybound_class) :: bnd ! Boundary variables to drive model type(ydata_class) :: dta ! Data variables for comparison type(yregions_class) :: reg ! Regionally aggregated variables end type Likewise the module variables are defined in a similar way, e.g. ytopo_class that defines variables and parameters associated with the topography: type ytopo_class type(ytopo_param_class) :: par ! Parameters type(ytopo_state_class) :: now ! Variables end type Submodules such as ytopo_class include parameter definitions relevant to topography calculations, as well as all variables that define the state of the domain being modeled. Example model domain intialization The below code snippet shows an example of how to initialize an instance of Yelmo inside of a program, run the model forward in time and then terminate the instance. ! === Initialize ice sheet model ===== ! General initialization of yelmo constants (used globally, only once per program) call yelmo_global_init(path_const) ! Initialize Yelmo objects (multiple yelmo objects can be initialized if needed) ! In this case `yelmo1` is the Yelmo object to initialize and `path_par` is the ! path to the parameter file to load for the configuration information. This ! command will also initialize the domain grid and load initial topographic ! variables. call yelmo_init(yelmo1,filename=path_par,grid_def=\"file\",time=time_init) ! === Load initial boundary conditions for current time and yelmo state ===== ! These variables can be loaded from a file, or passed from another ! component being simulated. Yelmo does not care about the source, ! it only needs all variables in the `bnd` class to be populated. ! ybound: z_bed, z_sl, H_sed, H_w, smb, T_srf, bmb_shlf, T_shlf, Q_geo yelmo1%bnd%z_bed = [2D array] yelmo1%bnd%z_sl = [2D array] yelmo1%bnd%H_sed = [2D array] yelmo1%bnd%H_w = [2D array] yelmo1%bnd%smb = [2D array] yelmo1%bnd%T_srf = [2D array] yelmo1%bnd%bmb_shlf = [2D array] yelmo1%bnd%T_shlf = [2D array] yelmo1%bnd%Q_geo = [2D array] ! Print summary of initial boundary conditions call yelmo_print_bound(yelmo1%bnd) ! Next, initialize the state variables (dyn,therm,mat) ! (in this case, initialize temps with robin method) call yelmo_init_state(yelmo1,time=time_init,thrm_method=\"robin\") ! Run yelmo for eg 100.0 years with constant boundary conditions and topo ! to equilibrate thermodynamics and dynamics ! (impose a constant, small dt=1yr to reduce possibility for instabilities) call yelmo_update_equil(yelmo1,time,time_tot=100.0,topo_fixed=.FALSE.,dt=1.0) ! == YELMO INITIALIZATION COMPLETE == ! Note: the above routines `yelmo_init_state` and `yelmo_update_equil` ! are optional, if the user prefers another way to initialize the state variables. ! == Start time looping and run the model == ! Advance timesteps do n = 1, ntot ! Get current time time = time_init + n*dt ! Update the Yelmo ice sheet call yelmo_update(yelmo1,time) ! Here you may be updating `yelmo1%bnd` variables to drive the model transiently. end do ! == Finalize Yelmo instance == call yelmo_end(yelmo1,time=time) That's it! See Getting started to see how to get the code, compile a test program and run simulations.","title":"Home"},{"location":"#yelmo","text":"Welcome to Yelmo , an easy to use continental ice sheet model. Yelmo is a 3D ice-sheet-shelf model solving for the coupled dynamics and thermodynamics of the ice sheet system. Yelmo can be used for idealized simulations, stand-alone ice sheet simulations and fully coupled ice-sheet and climate simulations. Yelmo has been designed to operate as a stand-alone model or to be easily plugged in as a module in another program. The key to its flexibility is that no variables are defined globally and parameters are defined according to the domain being modeled. In this way, all variables and calculations are store in an object that entirely represents the model domain. The physics and design of Yelmo are described in the following article: Robinson, A., Alvarez-Solas, J., Montoya, M., Goelzer, H., Greve, R., and Ritz, C.: Description and validation of the ice-sheet model Yelmo (version 1.0), Geosci. Model Dev., 13, 2805\u20132823, https://doi.org/10.5194/gmd-13-2805-2020 , 2020. The Yelmo code repository can be found here: https://github.com/palma-ice/yelmo","title":"Yelmo"},{"location":"#general-model-structure-classes-and-usage","text":"","title":"General model structure - classes and usage"},{"location":"#yelmo_class","text":"The Yelmo class defines all data related to a model domain, such as Greenland or Antarctica. As seen below in the yelmo_class defintion, the 'class' is simply a user-defined Fortran type that contains additional types representing various parameters, variables or sets of module variables. type yelmo_class type(yelmo_param_class) :: par ! General domain parameters type(ygrid_class) :: grd ! Grid definition type(ytopo_class) :: tpo ! Topography variables type(ydyn_class) :: dyn ! Dynamics variables type(ymat_class) :: mat ! Material variables type(ytherm_class) :: thrm ! Thermodynamics variables type(ybound_class) :: bnd ! Boundary variables to drive model type(ydata_class) :: dta ! Data variables for comparison type(yregions_class) :: reg ! Regionally aggregated variables end type Likewise the module variables are defined in a similar way, e.g. ytopo_class that defines variables and parameters associated with the topography: type ytopo_class type(ytopo_param_class) :: par ! Parameters type(ytopo_state_class) :: now ! Variables end type Submodules such as ytopo_class include parameter definitions relevant to topography calculations, as well as all variables that define the state of the domain being modeled.","title":"yelmo_class"},{"location":"#example-model-domain-intialization","text":"The below code snippet shows an example of how to initialize an instance of Yelmo inside of a program, run the model forward in time and then terminate the instance. ! === Initialize ice sheet model ===== ! General initialization of yelmo constants (used globally, only once per program) call yelmo_global_init(path_const) ! Initialize Yelmo objects (multiple yelmo objects can be initialized if needed) ! In this case `yelmo1` is the Yelmo object to initialize and `path_par` is the ! path to the parameter file to load for the configuration information. This ! command will also initialize the domain grid and load initial topographic ! variables. call yelmo_init(yelmo1,filename=path_par,grid_def=\"file\",time=time_init) ! === Load initial boundary conditions for current time and yelmo state ===== ! These variables can be loaded from a file, or passed from another ! component being simulated. Yelmo does not care about the source, ! it only needs all variables in the `bnd` class to be populated. ! ybound: z_bed, z_sl, H_sed, H_w, smb, T_srf, bmb_shlf, T_shlf, Q_geo yelmo1%bnd%z_bed = [2D array] yelmo1%bnd%z_sl = [2D array] yelmo1%bnd%H_sed = [2D array] yelmo1%bnd%H_w = [2D array] yelmo1%bnd%smb = [2D array] yelmo1%bnd%T_srf = [2D array] yelmo1%bnd%bmb_shlf = [2D array] yelmo1%bnd%T_shlf = [2D array] yelmo1%bnd%Q_geo = [2D array] ! Print summary of initial boundary conditions call yelmo_print_bound(yelmo1%bnd) ! Next, initialize the state variables (dyn,therm,mat) ! (in this case, initialize temps with robin method) call yelmo_init_state(yelmo1,time=time_init,thrm_method=\"robin\") ! Run yelmo for eg 100.0 years with constant boundary conditions and topo ! to equilibrate thermodynamics and dynamics ! (impose a constant, small dt=1yr to reduce possibility for instabilities) call yelmo_update_equil(yelmo1,time,time_tot=100.0,topo_fixed=.FALSE.,dt=1.0) ! == YELMO INITIALIZATION COMPLETE == ! Note: the above routines `yelmo_init_state` and `yelmo_update_equil` ! are optional, if the user prefers another way to initialize the state variables. ! == Start time looping and run the model == ! Advance timesteps do n = 1, ntot ! Get current time time = time_init + n*dt ! Update the Yelmo ice sheet call yelmo_update(yelmo1,time) ! Here you may be updating `yelmo1%bnd` variables to drive the model transiently. end do ! == Finalize Yelmo instance == call yelmo_end(yelmo1,time=time) That's it! See Getting started to see how to get the code, compile a test program and run simulations.","title":"Example model domain intialization"},{"location":"dependencies/","text":"Dependencies Yelmo is dependent on the following libraries: NetCDF Library of Iterative Solvers for Linear Systems [Optional] 'runner' Python library (alex-robinson fork) Installation tips for each dependency can be found below. Installing NetCDF (preferably version 4.0 or higher) The NetCDF library is typically available with different distributions (Linux, Mac, etc). Along with installing libnetcdf , it will be necessary to install the package libnetcdf-dev . Installing the NetCDF viewing program ncview is also recommended. If you want to install NetCDF from source, then you must install both the netcdf-c and subsequently netcdf-fortran libraries. The source code and installation instructions are available from the Unidata website: https://www.unidata.ucar.edu/software/netcdf/docs/getting_and_building_netcdf.html Installing LIS Download the LIS source: https://www.ssisc.org/lis/ Configure the package (where is the desired installation location), and install it in the location of your choice (below defined as $LISROOT ). Also, make sure to enable the Fortran90 interface: cd lis-2.0.18 ./configure --prefix=$LISROOT --enable-f90 make make install make install check Note: make sure to set the environment variables CC and FC , in order to set a specific compiler, for example for gcc/gfortran use the following configure command: CC=gcc FC=gfortran ./configure --prefix=$LISROOT --enable-f90 Add LIS path to the LD_LIBRARY_PATH in .bash_profile , .bashrc or .bash_aliases : # lis library paths LD_LIBRARY_PATH=$LISROOT/lib:$LD_LIBRARY_PATH export LD_LIBRARY_PATH That's it. LIS should now be available to use with Yelmo. Installing runner Install runner to your system's Python installation via pip , along with dependency tabulate . pip install https://github.com/alex-robinson/runner/archive/refs/heads/master.zip pip install tabulate That's it! Now check that system command job is available by running job -h . Note that install method python setup.py install should be avoided if possible to maintain Python system integrity.","title":"Dependencies"},{"location":"dependencies/#dependencies","text":"Yelmo is dependent on the following libraries: NetCDF Library of Iterative Solvers for Linear Systems [Optional] 'runner' Python library (alex-robinson fork) Installation tips for each dependency can be found below.","title":"Dependencies"},{"location":"dependencies/#installing-netcdf-preferably-version-40-or-higher","text":"The NetCDF library is typically available with different distributions (Linux, Mac, etc). Along with installing libnetcdf , it will be necessary to install the package libnetcdf-dev . Installing the NetCDF viewing program ncview is also recommended. If you want to install NetCDF from source, then you must install both the netcdf-c and subsequently netcdf-fortran libraries. The source code and installation instructions are available from the Unidata website: https://www.unidata.ucar.edu/software/netcdf/docs/getting_and_building_netcdf.html","title":"Installing NetCDF (preferably version 4.0 or higher)"},{"location":"dependencies/#installing-lis","text":"Download the LIS source: https://www.ssisc.org/lis/ Configure the package (where is the desired installation location), and install it in the location of your choice (below defined as $LISROOT ). Also, make sure to enable the Fortran90 interface: cd lis-2.0.18 ./configure --prefix=$LISROOT --enable-f90 make make install make install check Note: make sure to set the environment variables CC and FC , in order to set a specific compiler, for example for gcc/gfortran use the following configure command: CC=gcc FC=gfortran ./configure --prefix=$LISROOT --enable-f90 Add LIS path to the LD_LIBRARY_PATH in .bash_profile , .bashrc or .bash_aliases : # lis library paths LD_LIBRARY_PATH=$LISROOT/lib:$LD_LIBRARY_PATH export LD_LIBRARY_PATH That's it. LIS should now be available to use with Yelmo.","title":"Installing LIS"},{"location":"dependencies/#installing-runner","text":"Install runner to your system's Python installation via pip , along with dependency tabulate . pip install https://github.com/alex-robinson/runner/archive/refs/heads/master.zip pip install tabulate That's it! Now check that system command job is available by running job -h . Note that install method python setup.py install should be avoided if possible to maintain Python system integrity.","title":"Installing runner"},{"location":"example-programs/","text":"Example programs The Yelmo base code provides a static library interface that can be used in other programs, as well as a couple of stand-alone programs for running certain benchmarks. Here we provide more examples of how to use Yelmo: Program template to connect with other models/components. Stand-alone ice sheet with full boundary forcing. In both cases, it is necessary to download the Yelmo repository separately, as well as compile the Yelmo static library (see Getting started ). Program template This is a minimalistic setup that allows you to run Yelmo with no dependencies and a straightforward Makefile. This template can be used to design a new stand-alone Yelmo experiment, or to provide guidance when adding Yelmo to another program. Clone the repository from https://github.com/palma-ice/yelmot Stand-alone ice sheet with full boundary forcing (yelmox) This setup is suitable for glacial-cycle simulations, future simulations or any other typical (realistic) ice-sheet model simulation. Clone the repository from https://github.com/palma-ice/yelmox","title":"Examples"},{"location":"example-programs/#example-programs","text":"The Yelmo base code provides a static library interface that can be used in other programs, as well as a couple of stand-alone programs for running certain benchmarks. Here we provide more examples of how to use Yelmo: Program template to connect with other models/components. Stand-alone ice sheet with full boundary forcing. In both cases, it is necessary to download the Yelmo repository separately, as well as compile the Yelmo static library (see Getting started ).","title":"Example programs"},{"location":"example-programs/#program-template","text":"This is a minimalistic setup that allows you to run Yelmo with no dependencies and a straightforward Makefile. This template can be used to design a new stand-alone Yelmo experiment, or to provide guidance when adding Yelmo to another program. Clone the repository from https://github.com/palma-ice/yelmot","title":"Program template"},{"location":"example-programs/#stand-alone-ice-sheet-with-full-boundary-forcing-yelmox","text":"This setup is suitable for glacial-cycle simulations, future simulations or any other typical (realistic) ice-sheet model simulation. Clone the repository from https://github.com/palma-ice/yelmox","title":"Stand-alone ice sheet with full boundary forcing (yelmox)"},{"location":"getting-started/","text":"Getting started Here you can find the basic information and steps needed to get Yelmo running. Super-quick start A summary of commands to get started is given below. For more detailed information see subsequent sections. # Clone repository git clone https://github.com/palma-ice/yelmo.git git clone git@github.com:palma-ice/yelmo.git # via ssh # Enter directory and run configuration script cd yelmo python config.py config/pik_ifort # Compile the benchmarks program make clean make benchmarks # Run a test simulation of the EISMINT1-moving experiment ./runylmo -r -e benchmarks -o output/eismint1-moving -n par-gmd/yelmo_EISMINT_moving.nml # Compile the initmip program and run the default simulation of Antarctica make initmip ./runylmo -r -e initmip -o output/ant-pd -n par-gmd/yelmo_Antarctica.nml Dependencies See: Dependencies for installation tips. NetCDF library (preferably version 4.0 or higher) LIS: Library of Iterative Solvers for Linear Systems [Optional] Python 3.x, which is only needed for automatic configuration of the Makefile and the use of the script runylmo for job preparation and submission. [Optional] 'runner' Python library: https://github.com/alex-robinson/runner . Used for changing parameters at the command line using runylmo , and for running ensembles. Directory structure config/ Configuration files for compilation on different systems. input/ Location of any input data needed by the model. libs/ Auxiliary libraries nesecessary for running the model. libyelmo/ Folder containing all compiled files in a standard way with lib/, include/ and bin/ folders. output/ Default location for model output. par/ Default parameter files that manage the model configuration. src/ Source code for Yelmo. tests/ Source code and analysis scripts for specific model benchmarks and tests. Usage Follow the steps below to (1) obtain the code, (2) configure the Makefile for your system, (3) compile the Yelmo static library and an executable program and (4) run a test simulation. 1. Get the code. Clone the repository from https://github.com/palma-ice/yelmo : # Clone repository git clone https://github.com/palma-ice/yelmo.git $YELMOROOT git clone git@github.com:palma-ice/yelmo.git $YELMOROOT # via ssh cd $YELMOROOT where $YELMOROOT is the installation directory. If you plan to make changes to the code, it is wise to check out a new branch: git checkout -b user-dev You should now be working on the branch user-dev . 2. Create the system-specific Makefile. To compile Yelmo, you need to generate a Makefile that is appropriate for your system. In the folder config , you need to specify a configuration file that defines the compiler and flags, including definition of the paths to the NetCDF and LIS libraries. You can use another file in the config folder as a template, e.g., cd config cp pik_ifort myhost_mycompiler then modify the file myhost_mycompiler to match your paths. Back in $YELMOROOT , you can then generate your Makefile with the provided python configuration script: cd $YELMOROOT python config.py config/myhost_mycompiler The result should be a Makefile in $YELMOROOT that is ready for use. Alternative configuration - quickstart with Docker and VS Code Instead of a manual install, one way to get up and running quickly with Yelmo is with VS Code and Docker. It works on any plattform and uses a Linux based container. You don't need to know Docker or VS Code to get started. Just install the following: Docker VS Code install the remote development extension Then make sure that Docker is running and start VS Code. Open the folder with the Yelmo code. Say Yes, when VS Code asks you if you want to open it in the container. Now you can directly go to step 3 below, just make sure that you use the terminal in VS Code. 3. Compile the code. Now you are ready to compile Yelmo as a static library: make clean # This step is very important to avoid errors!! make yelmo-static [debug=1] This will compile all of the Yelmo modules and libraries (as defined in config/Makefile_yelmo.mk ), and link them in a static library. All compiled files can be found in the folder libyelmo/ . Once the static library has been compiled, it can be used inside of external Fortran programs and modules via the statement use yelmo . To include/link yelmo-static during compilation of another program, its location must be defined: INC_YELMO = -I${YELMOROOT}/include LIB_YELMO = -L${YELMOROOT}/include -lyelmo Alternatively, several test programs exist in the folder tests/ to run Yelmo as a stand-alone ice sheet. For example, it's possible to run different EISMINT benchmarks, MISMIP benchmarks and the ISIMIP6 INITMIP simulation for Greenland, respectively: make benchmarks # compiles the program `libyelmo/bin/yelmo_benchmarks.x` make mismip # compiles the program `libyelmo/bin/yelmo_mismip.x` make initmip # compiles the program `libyelmo/bin/yelmo_initmip.x` The Makefile additionally allows you to specify debugging compiler flags with the option debug=1 , in case you need to debug the code (e.g., make benchmarks debug=1 ). Using this option, the code will run much slower, so this option is not recommended unless necessary. 4. Run the model. Once an executable has been created, you can run the model. This can be achieved via the included Python job submission script runylmo . The following steps are carried out via the script: The output directory is created. The executable is copied to the output directory The relevant parameter files are copied to the output directory. Links to the input data paths ( input and ice_data ) are created in the output directory. Note that many simulations, such as benchmark experiments, do not depend on these external data sources, but the links are made anyway. The executable is run from the output directory, either as a background process or it is submitted to the queue via sbatch (the SLURM workload manager). To run a benchmark simulation, for example, use the following command: ./runylmo -r -e benchmarks -o output/test -n par/yelmo_EISMINT.nml where the option -r implies that the model should be run as a background process. If this is omitted, then the output directory will be populated, but no executable will be run, while -s instead will submit the simulation to cluster queue system instead of running in the background. The option -e lets you specify the executable. For some standard cases, shortcuts have been created: benchmarks = libyelmo/bin/yelmo_benchmarks.x mismip = libyelmo/bin/yemo_mismip.x initmip = libyelmo/bin/yelmo_initmip.x The last two mandatory arguments -o OUTDIR and -n PAR_PATH are the output/run directory and the parameter file to be used for this simulation, respectively. In the case of the above simulation, the output directory is defined as output/test , where all model parameters (loaded from the file par/yelmo_EISMINT.nml ) and model output can be found. It is also possible to modify parameters inline via the option -p KEY=VAL [KEY=VAL ...] . The parameter should be specified with its namelist group and its name. E.g., to change the resolution of the EISMINT benchmark experiment to 10km, use: ./runylmo -r -e benchmarks -o output/test -n par/yelmo_EISMINT.nml -p ctrl.dx=10 See runylmo -h for more details on the run script. Test cases The published model description includes several test simulations for validation of the model's performance. The following section describes how to perform these tests using the same model version documented in the article. From this point, it is assumed that the user has already configured the model for their system (see https://palma-ice.github.io/yelmo-docs) and is ready to compile the mode. 1. EISMINT1 moving margin experiment To perform the moving margin experiment, compile the benchmarks executable and call it with the EISMINT parameter file: make benchmarks ./runylmo -r -e benchmarks -o output/eismint-moving -n par-gmd/yelmo_EISMINT_moving.nml 2. EISMINT2 EXPA To perform Experiment A from the EISMINT2 benchmarks, compile the benchmarks executable and call it with the EXPA parameter file: make benchmarks ./runylmo -r -e benchmarks -o output/eismint-expa -n par-gmd/yelmo_EISMINT_expa.nml 3. EISMINT2 EXPF To perform Experiment F from the EISMINT2 benchmarks, compile the benchmarks executable and call it with the EXPF parameter file: make benchmarks ./runylmo -r -e benchmarks -o output/eismint-expf -n par-gmd/yelmo_EISMINT_expf.nml 4. MISMIP RF To perform the MISMIP rate factor experiment, compile the mismip executable and call it with the MISMIP parameter file the three parameter permutations of interest (default, subgrid and subgrid+gl-scaling): make mismip ./runylmo -r -e mismip -o output/mismip-rf-0 -n par-gmd/yelmo_MISMIP3D.nml -p ydyn.beta_gl_stag=0 ydyn.beta_gl_scale=0 ./runylmo -r -e mismip -o output/mismip-rf-1 -n par-gmd/yelmo_MISMIP3D.nml -p ydyn.beta_gl_stag=3 ydyn.beta_gl_scale=0 ./runylmo -r -e mismip -o output/mismip-rf-2 -n par-gmd/yelmo_MISMIP3D.nml -p ydyn.beta_gl_stag=3 ydyn.beta_gl_scale=2 To additionally change the resolution of the simulations change the parameter mismip.dx , e.g. for the default simulation with 10km resolution , call: ./runylmo -r -e mismip -o output/mismip-rf-0-10km -n par-gmd/yelmo_MISMIP3D.nml -p ydyn.beta_gl_stag=0 ydyn.beta_gl_scale=0 mismip.dx=10 5. Age profile experiments To perform the age profile experiments, compile the Fortran program tests/test_icetemp.f90 and run it: make icetemp ./libyelmo/bin/test_icetemp.x To perform the different permutations, it is necessary to recompile for single or double precision after changing the precision parameter prec in the file src/yelmo_defs.f90 . The number of vertical grid points can be specified in the main program file, as well as the output filename. 6. Antarctica present-day and glacial simulations To perform the Antarctica simulations as presented in the paper, it is necessary to compile the initmip executable and run with the present-day (pd) and glacial (lgm) parameter values: make initmip ./runylmo -r -e initmip -o output/ant-pd -n par-gmd/yelmo_Antarctica.nml -p ctrl.clim_nm=\"clim_pd\" ./runylmo -r -e initmip -o output/ant-lgm -n par-gmd/yelmo_Antarctica.nml -p ctrl.clim_nm=\"clim_lgm\"","title":"Getting started"},{"location":"getting-started/#getting-started","text":"Here you can find the basic information and steps needed to get Yelmo running.","title":"Getting started"},{"location":"getting-started/#super-quick-start","text":"A summary of commands to get started is given below. For more detailed information see subsequent sections. # Clone repository git clone https://github.com/palma-ice/yelmo.git git clone git@github.com:palma-ice/yelmo.git # via ssh # Enter directory and run configuration script cd yelmo python config.py config/pik_ifort # Compile the benchmarks program make clean make benchmarks # Run a test simulation of the EISMINT1-moving experiment ./runylmo -r -e benchmarks -o output/eismint1-moving -n par-gmd/yelmo_EISMINT_moving.nml # Compile the initmip program and run the default simulation of Antarctica make initmip ./runylmo -r -e initmip -o output/ant-pd -n par-gmd/yelmo_Antarctica.nml","title":"Super-quick start"},{"location":"getting-started/#dependencies","text":"See: Dependencies for installation tips. NetCDF library (preferably version 4.0 or higher) LIS: Library of Iterative Solvers for Linear Systems [Optional] Python 3.x, which is only needed for automatic configuration of the Makefile and the use of the script runylmo for job preparation and submission. [Optional] 'runner' Python library: https://github.com/alex-robinson/runner . Used for changing parameters at the command line using runylmo , and for running ensembles.","title":"Dependencies"},{"location":"getting-started/#directory-structure","text":"config/ Configuration files for compilation on different systems. input/ Location of any input data needed by the model. libs/ Auxiliary libraries nesecessary for running the model. libyelmo/ Folder containing all compiled files in a standard way with lib/, include/ and bin/ folders. output/ Default location for model output. par/ Default parameter files that manage the model configuration. src/ Source code for Yelmo. tests/ Source code and analysis scripts for specific model benchmarks and tests.","title":"Directory structure"},{"location":"getting-started/#usage","text":"Follow the steps below to (1) obtain the code, (2) configure the Makefile for your system, (3) compile the Yelmo static library and an executable program and (4) run a test simulation.","title":"Usage"},{"location":"getting-started/#1-get-the-code","text":"Clone the repository from https://github.com/palma-ice/yelmo : # Clone repository git clone https://github.com/palma-ice/yelmo.git $YELMOROOT git clone git@github.com:palma-ice/yelmo.git $YELMOROOT # via ssh cd $YELMOROOT where $YELMOROOT is the installation directory. If you plan to make changes to the code, it is wise to check out a new branch: git checkout -b user-dev You should now be working on the branch user-dev .","title":"1. Get the code."},{"location":"getting-started/#2-create-the-system-specific-makefile","text":"To compile Yelmo, you need to generate a Makefile that is appropriate for your system. In the folder config , you need to specify a configuration file that defines the compiler and flags, including definition of the paths to the NetCDF and LIS libraries. You can use another file in the config folder as a template, e.g., cd config cp pik_ifort myhost_mycompiler then modify the file myhost_mycompiler to match your paths. Back in $YELMOROOT , you can then generate your Makefile with the provided python configuration script: cd $YELMOROOT python config.py config/myhost_mycompiler The result should be a Makefile in $YELMOROOT that is ready for use.","title":"2. Create the system-specific Makefile."},{"location":"getting-started/#alternative-configuration-quickstart-with-docker-and-vs-code","text":"Instead of a manual install, one way to get up and running quickly with Yelmo is with VS Code and Docker. It works on any plattform and uses a Linux based container. You don't need to know Docker or VS Code to get started. Just install the following: Docker VS Code install the remote development extension Then make sure that Docker is running and start VS Code. Open the folder with the Yelmo code. Say Yes, when VS Code asks you if you want to open it in the container. Now you can directly go to step 3 below, just make sure that you use the terminal in VS Code.","title":"Alternative configuration - quickstart with Docker and VS Code"},{"location":"getting-started/#3-compile-the-code","text":"Now you are ready to compile Yelmo as a static library: make clean # This step is very important to avoid errors!! make yelmo-static [debug=1] This will compile all of the Yelmo modules and libraries (as defined in config/Makefile_yelmo.mk ), and link them in a static library. All compiled files can be found in the folder libyelmo/ . Once the static library has been compiled, it can be used inside of external Fortran programs and modules via the statement use yelmo . To include/link yelmo-static during compilation of another program, its location must be defined: INC_YELMO = -I${YELMOROOT}/include LIB_YELMO = -L${YELMOROOT}/include -lyelmo Alternatively, several test programs exist in the folder tests/ to run Yelmo as a stand-alone ice sheet. For example, it's possible to run different EISMINT benchmarks, MISMIP benchmarks and the ISIMIP6 INITMIP simulation for Greenland, respectively: make benchmarks # compiles the program `libyelmo/bin/yelmo_benchmarks.x` make mismip # compiles the program `libyelmo/bin/yelmo_mismip.x` make initmip # compiles the program `libyelmo/bin/yelmo_initmip.x` The Makefile additionally allows you to specify debugging compiler flags with the option debug=1 , in case you need to debug the code (e.g., make benchmarks debug=1 ). Using this option, the code will run much slower, so this option is not recommended unless necessary.","title":"3. Compile the code."},{"location":"getting-started/#4-run-the-model","text":"Once an executable has been created, you can run the model. This can be achieved via the included Python job submission script runylmo . The following steps are carried out via the script: The output directory is created. The executable is copied to the output directory The relevant parameter files are copied to the output directory. Links to the input data paths ( input and ice_data ) are created in the output directory. Note that many simulations, such as benchmark experiments, do not depend on these external data sources, but the links are made anyway. The executable is run from the output directory, either as a background process or it is submitted to the queue via sbatch (the SLURM workload manager). To run a benchmark simulation, for example, use the following command: ./runylmo -r -e benchmarks -o output/test -n par/yelmo_EISMINT.nml where the option -r implies that the model should be run as a background process. If this is omitted, then the output directory will be populated, but no executable will be run, while -s instead will submit the simulation to cluster queue system instead of running in the background. The option -e lets you specify the executable. For some standard cases, shortcuts have been created: benchmarks = libyelmo/bin/yelmo_benchmarks.x mismip = libyelmo/bin/yemo_mismip.x initmip = libyelmo/bin/yelmo_initmip.x The last two mandatory arguments -o OUTDIR and -n PAR_PATH are the output/run directory and the parameter file to be used for this simulation, respectively. In the case of the above simulation, the output directory is defined as output/test , where all model parameters (loaded from the file par/yelmo_EISMINT.nml ) and model output can be found. It is also possible to modify parameters inline via the option -p KEY=VAL [KEY=VAL ...] . The parameter should be specified with its namelist group and its name. E.g., to change the resolution of the EISMINT benchmark experiment to 10km, use: ./runylmo -r -e benchmarks -o output/test -n par/yelmo_EISMINT.nml -p ctrl.dx=10 See runylmo -h for more details on the run script.","title":"4. Run the model."},{"location":"getting-started/#test-cases","text":"The published model description includes several test simulations for validation of the model's performance. The following section describes how to perform these tests using the same model version documented in the article. From this point, it is assumed that the user has already configured the model for their system (see https://palma-ice.github.io/yelmo-docs) and is ready to compile the mode.","title":"Test cases"},{"location":"getting-started/#1-eismint1-moving-margin-experiment","text":"To perform the moving margin experiment, compile the benchmarks executable and call it with the EISMINT parameter file: make benchmarks ./runylmo -r -e benchmarks -o output/eismint-moving -n par-gmd/yelmo_EISMINT_moving.nml","title":"1. EISMINT1 moving margin experiment"},{"location":"getting-started/#2-eismint2-expa","text":"To perform Experiment A from the EISMINT2 benchmarks, compile the benchmarks executable and call it with the EXPA parameter file: make benchmarks ./runylmo -r -e benchmarks -o output/eismint-expa -n par-gmd/yelmo_EISMINT_expa.nml","title":"2. EISMINT2 EXPA"},{"location":"getting-started/#3-eismint2-expf","text":"To perform Experiment F from the EISMINT2 benchmarks, compile the benchmarks executable and call it with the EXPF parameter file: make benchmarks ./runylmo -r -e benchmarks -o output/eismint-expf -n par-gmd/yelmo_EISMINT_expf.nml","title":"3. EISMINT2 EXPF"},{"location":"getting-started/#4-mismip-rf","text":"To perform the MISMIP rate factor experiment, compile the mismip executable and call it with the MISMIP parameter file the three parameter permutations of interest (default, subgrid and subgrid+gl-scaling): make mismip ./runylmo -r -e mismip -o output/mismip-rf-0 -n par-gmd/yelmo_MISMIP3D.nml -p ydyn.beta_gl_stag=0 ydyn.beta_gl_scale=0 ./runylmo -r -e mismip -o output/mismip-rf-1 -n par-gmd/yelmo_MISMIP3D.nml -p ydyn.beta_gl_stag=3 ydyn.beta_gl_scale=0 ./runylmo -r -e mismip -o output/mismip-rf-2 -n par-gmd/yelmo_MISMIP3D.nml -p ydyn.beta_gl_stag=3 ydyn.beta_gl_scale=2 To additionally change the resolution of the simulations change the parameter mismip.dx , e.g. for the default simulation with 10km resolution , call: ./runylmo -r -e mismip -o output/mismip-rf-0-10km -n par-gmd/yelmo_MISMIP3D.nml -p ydyn.beta_gl_stag=0 ydyn.beta_gl_scale=0 mismip.dx=10","title":"4. MISMIP RF"},{"location":"getting-started/#5-age-profile-experiments","text":"To perform the age profile experiments, compile the Fortran program tests/test_icetemp.f90 and run it: make icetemp ./libyelmo/bin/test_icetemp.x To perform the different permutations, it is necessary to recompile for single or double precision after changing the precision parameter prec in the file src/yelmo_defs.f90 . The number of vertical grid points can be specified in the main program file, as well as the output filename.","title":"5. Age profile experiments"},{"location":"getting-started/#6-antarctica-present-day-and-glacial-simulations","text":"To perform the Antarctica simulations as presented in the paper, it is necessary to compile the initmip executable and run with the present-day (pd) and glacial (lgm) parameter values: make initmip ./runylmo -r -e initmip -o output/ant-pd -n par-gmd/yelmo_Antarctica.nml -p ctrl.clim_nm=\"clim_pd\" ./runylmo -r -e initmip -o output/ant-lgm -n par-gmd/yelmo_Antarctica.nml -p ctrl.clim_nm=\"clim_lgm\"","title":"6. Antarctica present-day and glacial simulations"},{"location":"notes/","text":"Notes master to main Following updated conventions, the default branch is now called main and the branch master has been deleted. To update a working copy locally that already contains a master branch and therefore points to it as the default branch, the following steps should be applied: Get the branch main . Delete the local branch master . Make sure your local repository sees main as the default branch. # Get all branch information from the origin (github): git fetch --all # Get onto the new default branch: git checkout main # Delete the branch master: git branch -d master # Clean up any branches that no longer exist at origin: git fetch --prune origin # Set the local 'head' to whatever is specified at the origin (which will be main): git remote set-head origin -a Done! Now your local copy should work like normal, with main instead of master . Thermodynamics equations Ice column Prognostic equation: \\frac{\\partial T}{\\partial t} = \\frac{k}{\\rho c} \\frac{\\partial^2 T}{\\partial z^2} - u \\frac{\\partial T}{\\partial x} - v \\frac{\\partial T}{\\partial y} - w \\frac{\\partial T}{\\partial z} + \\frac{\\Phi}{\\rho c} Ice surface boundary condition: T(z=z_{\\rm srf}) = {\\rm min}(T_{\\rm 2m},T_0) Ice base (temperate) boundary condition: T(z=z_{\\rm bed}) = T_{\\rm pmp} Ice base (frozen) boundary condition: k \\frac{\\partial T}{\\partial z} = k_r \\frac{\\partial T_r}{\\partial z} Note, the following internal Yelmo variables are defined for convenience: Q_{\\rm ice,b} = -k \\frac{\\partial T}{\\partial z}; \\quad Q_{\\rm rock} = -k_r \\frac{\\partial T_r}{\\partial z} Bedrock column Prognostic equation: \\frac{\\partial T_r}{\\partial t} = \\frac{k_r}{\\rho_r c_r} \\frac{\\partial^2 T_r}{\\partial z^2} Bedrock surface boundary condition: T_r(z=z_{\\rm bed}) = T(z=z_{\\rm bed}) Bedrock base boundary condition: \\frac{\\partial T_r}{\\partial z} = -\\frac{Q_{\\rm geo}}{k_r} Equilibrium bedrock In this case, the bedrock temperature profile is prescribed to the equilibrium linear temperature profile. The slope follows: \\frac{\\partial T_r}{\\partial z} = -\\frac{Q_{\\rm geo}}{k_r} and the bedrock surface temperature is given by the ice temperature at its base: T_r(z=z_{\\rm bed}) = T(z=z_{\\rm bed}) Active bedrock Yelmo calculates the temperature in the lithosphere along with the ice temperature. This can be achieved by assuming equilibrium conditions in the bedrock, i.e., that the temperature profile in the bedrock is always linear with T_lith_s = T_ice_b and the slope equal to dT/dz = -Q_geo / k_lith . Or, the temperature equation can be solved in the lithosphere together with the temperature in the ice column. The parameter block ytherm_lith controls how the lithosphere is calculated with ytherm_lith.method=['equil','active'] deciding the two cases above. Density of the upper lithosphere Heat capacity of the upper lithosphere In both SICOPOLIS and GRISLI, a value of cp = 1000.0 [J kg-1 K-1] is used (referenced in Rogozhina et al., 2012; Greve, 2005; Greve, 1997). This value is adopted in Yelmo as well. cp = 1000.0 ! [J kg-1 K-1] Heat conductivity of the upper lithosphere Note, Yelmo expects input parameter values in units of [J a-1 m-1 K-1] , while much literature uses [W m-1 K-1] . Given the number of seconds in a year sec_year = 31536000.0 , kt [W m-1 K-1] * sec_year = kt [J a-1 m-1 K-1] . Rogozhina et al. (2012) use kt = 2 [W m-1 K-1] for Greenland: kt = 6.3e7 ! [J a-1 m-1 K-1] This value is supported by L\u00f6sing et al. (2020), who perform a Bayesian inversion for GHF in Antarctica. Assuming exponentially decreasing heat production with depth, lower values of kt are supported (see Fig. 7b). In a study on the global thermal characteristics of the lithosphere, Cammarano and Guerri (2017) adopt an upper crust thermal conductivity of kt = 2.5 [W m-1 K-1] . To do: This study is also potentially relevant: https://link.springer.com/article/10.1186/s40517-020-0159-y . They show ranges of on the order of kt = 2-3 [W m-1 K-1] for the Canadian shield. The above value of kt = 2 [W m-1 K-1] = 6.3e7 [J a-1 m-1 K-1] is adopted as the default thermal conductivity of the upper crust in Yelmo. For historical context, see other estimates below. From Greve (1997) and Greve (2005): kt = 9.46e7 ! [J a-1 m-1 K-1] which is equivalent to kt = 3 [W m-1 K-1] . The source of this value is not known. From GRISLI: kt = 1.04e8 ! [J a-1 m-1 K-1] which is equivalent to kt = 3.3 [W m-1 K-1] . The source of this value is not known. How to read yelmo_check_kill output The subroutine yelmo_check_kill is used to see if any instability is arising in the model. If so, then a restart file is written at that moment (the earlier in the instability, the better), and the model is stopped with diagnostic output to the log file. Note that pc_eps is the parameter that defines our target error tolerance in the time stepping of ice thickness evolution. At each time step, the diagnosed model error pc_eta is compared with pc_eps . If pc_eta >> pc_eps , this is interpreted as instability and the model is stopped. Margin-front mass balance Following Pollard and DeConto (2012,2016), an ice-margin front melting scheme has been implemented that accounts for the melt rate along the vertical face of ice submerged by seawater. The frontal mass balance ($\\dot{f}$, m yr$^{-1}$) is calculated as: \\dot{f} = \\dot{b}_{\\rm eff} \\frac{A_f}{A_{\\rm tot}} \\theta_f where $\\dot{b} {\\rm eff}$ is the effective basal mass balance (the mean of the basal mass balance calculated for the ice-free neighbors), $A {\\rm tot}=\\Delta x \\Delta x$ is the horizontal grid area and $A_f$ is the area of the submerged faces (i.e., the sum of the depth of submerged ice for each face of the grid cell adjacent to an ice-free cell -- potentially four faces in total). $\\theta_f=10$ is a scaling coefficient that implies the face mass balance should be ~10 times higher than the basal mass balance (Pollard and DeConto, 2016, appendix). Calving schemes Here is a summary of calving schemes. Lipscomb et al. (2019) c = k_\\tau \\tau_{\\rm ec} where $k_\\tau$ (m yr$^{-1}$ Pa$^{-1}$) is an empirical constant and $\\tau_{\\rm ec}$ (Pa) is the effective calving stress, which is defined by: \\tau_{\\rm ec}^2 = \\max(\\tau_1,0)^2 + \\omega_2 \\max(\\tau_2,0)^2 $\\tau_1$ and $\\tau_2$ are the eigenvalues of the 2D horizontal deviatoric stress tensor and $\\omega_2$ is an empirical weighting constant. For partially ice-covered grid cells (with $f_{\\rm ice} < 1$), these stresses are taken from the upstream neighbor. The eigenvalues $\\tau_1$ and $\\tau_2$ are calculated from the depth-averaged (2D) stress tensor $\\tau_{\\rm ij}$ as follows. Given the stress tensor components $\\tau_{\\rm xx}$, $\\tau_{\\rm yy}$ and $\\tau_{\\rm xy}$, we can solve for the real roots $\\lambda$ of the tensor from the quadratic equation: a \\lambda^2 + b \\lambda + c = 0 where a = 1.0 \\\\ b = -(\\tau_{\\rm xx} + \\tau_{\\rm yy}) \\\\ c = \\tau_{\\rm xx}*\\tau_{\\rm yy} - \\tau_{\\rm xy}^2 glissade_velo_higher.F90: tau_xz(k,i,j) = tau_xz(k,i,j) + efvs_qp * du_dz ! 2 * efvs * eps_xz tau_yz(k,i,j) = tau_yz(k,i,j) + efvs_qp * dv_dz ! 2 * efvs * eps_yz tau_xx(k,i,j) = tau_xx(k,i,j) + 2.d0 * efvs_qp * du_dx ! 2 * efvs * eps_xx tau_yy(k,i,j) = tau_yy(k,i,j) + 2.d0 * efvs_qp * dv_dy ! 2 * efvs * eps_yy tau_xy(k,i,j) = tau_xy(k,i,j) + efvs_qp * (dv_dx + du_dy) ! 2 * efvs * eps_xy Vertical velocity w = u_b \\frac{\\partial b}{\\partial x} + v_b \\frac{\\partial b}{\\partial y} - \\int_b^z \\left( \\frac{\\partial u}{\\partial x} + \\frac{\\partial v}{\\partial y} \\right) dz' Ice margin, calving rates, mass conservation ajr, 2021-06-22 Through v1.42 , ice margins were not fully consistently treated in Yelmo. This has been thoroughly revised. Now the following should be true: The variable f_ice contains information of the ice area fraction of a grid cell. If f_ice=0 , no ice is present, if f_ice=1 , the cell is fully ice covered, and for a fractional value, this cell is designated an ice margin point with partial ice cover. To determine f_ice , we need to calculate the \"effective ice thickness\" of a grid point. For floating cells at the margin, the effective ice thickness is equivalent to either the ice thickness or the minimum ice thickness of the neighboring cell, whichever is larger. For grounded cells, the effective ice thickness must at least be that of 1/2 of the minimum ice thickness of a neighboring cell. With effective ice thickness known, f_ice = H_ice / H_eff . Any grid cell with fractional ice cover 0<f_ice<1 is designated dynamically inactive on its outer borders (borders with ice-free points). Thus before a new cell can be populated with ice, first the fractional cell must be filled to reach f_ice=1 . Velocity and the ssa solver now explicitly only treat cells with f_ice=1 . The dynamic-inactive borders are also enforced explicitly in the mass_conservation routine for safety. The calving rate is diagnosed as a lateral flux assuming a thickness of H_eff , but then is converted to a horizontal mass balance component applied to the whole cell. Additionally, it is possible to ensure 'residual calving' is applied to the upstream grid point of a margin cell, if the calving rate is large enough. This is done via the new routine calc_calving_residual . In the case of the simple and flux methods, applying full residual calving rates causes far too much calving. Rather a small amount of residual calving is applied to conservatively diminish the dynamic status of the upstream cell. The latter was implemented following CISM. Other important changes Major bug fix with thermodynamics and vertical velocity. The vertical velocity correction that was being applied to account for the sigma coordinates was incorrect. A correction must be applied to get the vertical velocity itself. Then another correction must be applied when calculating the vertical advection in the thermodynamics routine. Now this is hopefully done correctly. EISMINT EXPA and EXPF appear to work well. This may hopefully prove crucial for Javi's advance/retreat issues in Antarctica. Modified staggering of 3D viscosity to be done on horizontal ab-nodes, then averaged to the center. This follows a 'quadrature' approach and appears to be more rigorously close to actually integrating over the area. It's not clear how this might affect stability of ice streams (i.e., Daniel's results). Two-step mass balance with updates to f_ice in between, with more explicit tracking of all mass changes. Now a new variable mb_resid holds any threshold changes applied at the end of the mass balance update. I haven't checked in detail, but I hope all mass changes are now accounted for explicitly in the model. To do... vm-l19 calving method seems to be too sensitive. A reasonable coefficient value is kt=0.0001 instead of the value used by Lipscomb et al. (2019) of kt=0.0025 . Reducing where calv_resid is redistributed only to cells with the same ice thickness reduces this sensitivity. Needs checking. Threshold methods ( simple , flux , flux-grisli ) are not sensitive enough. Need to test how to apply calv_resid more robustly, or find another solution.","title":"Notes"},{"location":"notes/#notes","text":"","title":"Notes"},{"location":"notes/#master-to-main","text":"Following updated conventions, the default branch is now called main and the branch master has been deleted. To update a working copy locally that already contains a master branch and therefore points to it as the default branch, the following steps should be applied: Get the branch main . Delete the local branch master . Make sure your local repository sees main as the default branch. # Get all branch information from the origin (github): git fetch --all # Get onto the new default branch: git checkout main # Delete the branch master: git branch -d master # Clean up any branches that no longer exist at origin: git fetch --prune origin # Set the local 'head' to whatever is specified at the origin (which will be main): git remote set-head origin -a Done! Now your local copy should work like normal, with main instead of master .","title":"master to main"},{"location":"notes/#thermodynamics-equations","text":"","title":"Thermodynamics equations"},{"location":"notes/#ice-column","text":"Prognostic equation: \\frac{\\partial T}{\\partial t} = \\frac{k}{\\rho c} \\frac{\\partial^2 T}{\\partial z^2} - u \\frac{\\partial T}{\\partial x} - v \\frac{\\partial T}{\\partial y} - w \\frac{\\partial T}{\\partial z} + \\frac{\\Phi}{\\rho c} Ice surface boundary condition: T(z=z_{\\rm srf}) = {\\rm min}(T_{\\rm 2m},T_0) Ice base (temperate) boundary condition: T(z=z_{\\rm bed}) = T_{\\rm pmp} Ice base (frozen) boundary condition: k \\frac{\\partial T}{\\partial z} = k_r \\frac{\\partial T_r}{\\partial z} Note, the following internal Yelmo variables are defined for convenience: Q_{\\rm ice,b} = -k \\frac{\\partial T}{\\partial z}; \\quad Q_{\\rm rock} = -k_r \\frac{\\partial T_r}{\\partial z}","title":"Ice column"},{"location":"notes/#bedrock-column","text":"Prognostic equation: \\frac{\\partial T_r}{\\partial t} = \\frac{k_r}{\\rho_r c_r} \\frac{\\partial^2 T_r}{\\partial z^2} Bedrock surface boundary condition: T_r(z=z_{\\rm bed}) = T(z=z_{\\rm bed}) Bedrock base boundary condition: \\frac{\\partial T_r}{\\partial z} = -\\frac{Q_{\\rm geo}}{k_r}","title":"Bedrock column"},{"location":"notes/#equilibrium-bedrock","text":"In this case, the bedrock temperature profile is prescribed to the equilibrium linear temperature profile. The slope follows: \\frac{\\partial T_r}{\\partial z} = -\\frac{Q_{\\rm geo}}{k_r} and the bedrock surface temperature is given by the ice temperature at its base: T_r(z=z_{\\rm bed}) = T(z=z_{\\rm bed})","title":"Equilibrium bedrock"},{"location":"notes/#active-bedrock","text":"Yelmo calculates the temperature in the lithosphere along with the ice temperature. This can be achieved by assuming equilibrium conditions in the bedrock, i.e., that the temperature profile in the bedrock is always linear with T_lith_s = T_ice_b and the slope equal to dT/dz = -Q_geo / k_lith . Or, the temperature equation can be solved in the lithosphere together with the temperature in the ice column. The parameter block ytherm_lith controls how the lithosphere is calculated with ytherm_lith.method=['equil','active'] deciding the two cases above.","title":"Active bedrock"},{"location":"notes/#density-of-the-upper-lithosphere","text":"","title":"Density of the upper lithosphere"},{"location":"notes/#heat-capacity-of-the-upper-lithosphere","text":"In both SICOPOLIS and GRISLI, a value of cp = 1000.0 [J kg-1 K-1] is used (referenced in Rogozhina et al., 2012; Greve, 2005; Greve, 1997). This value is adopted in Yelmo as well. cp = 1000.0 ! [J kg-1 K-1]","title":"Heat capacity of the upper lithosphere"},{"location":"notes/#heat-conductivity-of-the-upper-lithosphere","text":"Note, Yelmo expects input parameter values in units of [J a-1 m-1 K-1] , while much literature uses [W m-1 K-1] . Given the number of seconds in a year sec_year = 31536000.0 , kt [W m-1 K-1] * sec_year = kt [J a-1 m-1 K-1] . Rogozhina et al. (2012) use kt = 2 [W m-1 K-1] for Greenland: kt = 6.3e7 ! [J a-1 m-1 K-1] This value is supported by L\u00f6sing et al. (2020), who perform a Bayesian inversion for GHF in Antarctica. Assuming exponentially decreasing heat production with depth, lower values of kt are supported (see Fig. 7b). In a study on the global thermal characteristics of the lithosphere, Cammarano and Guerri (2017) adopt an upper crust thermal conductivity of kt = 2.5 [W m-1 K-1] . To do: This study is also potentially relevant: https://link.springer.com/article/10.1186/s40517-020-0159-y . They show ranges of on the order of kt = 2-3 [W m-1 K-1] for the Canadian shield. The above value of kt = 2 [W m-1 K-1] = 6.3e7 [J a-1 m-1 K-1] is adopted as the default thermal conductivity of the upper crust in Yelmo. For historical context, see other estimates below. From Greve (1997) and Greve (2005): kt = 9.46e7 ! [J a-1 m-1 K-1] which is equivalent to kt = 3 [W m-1 K-1] . The source of this value is not known. From GRISLI: kt = 1.04e8 ! [J a-1 m-1 K-1] which is equivalent to kt = 3.3 [W m-1 K-1] . The source of this value is not known.","title":"Heat conductivity of the upper lithosphere"},{"location":"notes/#how-to-read-yelmo_check_kill-output","text":"The subroutine yelmo_check_kill is used to see if any instability is arising in the model. If so, then a restart file is written at that moment (the earlier in the instability, the better), and the model is stopped with diagnostic output to the log file. Note that pc_eps is the parameter that defines our target error tolerance in the time stepping of ice thickness evolution. At each time step, the diagnosed model error pc_eta is compared with pc_eps . If pc_eta >> pc_eps , this is interpreted as instability and the model is stopped.","title":"How to read yelmo_check_kill output"},{"location":"notes/#margin-front-mass-balance","text":"Following Pollard and DeConto (2012,2016), an ice-margin front melting scheme has been implemented that accounts for the melt rate along the vertical face of ice submerged by seawater. The frontal mass balance ($\\dot{f}$, m yr$^{-1}$) is calculated as: \\dot{f} = \\dot{b}_{\\rm eff} \\frac{A_f}{A_{\\rm tot}} \\theta_f where $\\dot{b} {\\rm eff}$ is the effective basal mass balance (the mean of the basal mass balance calculated for the ice-free neighbors), $A {\\rm tot}=\\Delta x \\Delta x$ is the horizontal grid area and $A_f$ is the area of the submerged faces (i.e., the sum of the depth of submerged ice for each face of the grid cell adjacent to an ice-free cell -- potentially four faces in total). $\\theta_f=10$ is a scaling coefficient that implies the face mass balance should be ~10 times higher than the basal mass balance (Pollard and DeConto, 2016, appendix).","title":"Margin-front mass balance"},{"location":"notes/#calving-schemes","text":"Here is a summary of calving schemes.","title":"Calving schemes"},{"location":"notes/#lipscomb-et-al-2019","text":"c = k_\\tau \\tau_{\\rm ec} where $k_\\tau$ (m yr$^{-1}$ Pa$^{-1}$) is an empirical constant and $\\tau_{\\rm ec}$ (Pa) is the effective calving stress, which is defined by: \\tau_{\\rm ec}^2 = \\max(\\tau_1,0)^2 + \\omega_2 \\max(\\tau_2,0)^2 $\\tau_1$ and $\\tau_2$ are the eigenvalues of the 2D horizontal deviatoric stress tensor and $\\omega_2$ is an empirical weighting constant. For partially ice-covered grid cells (with $f_{\\rm ice} < 1$), these stresses are taken from the upstream neighbor. The eigenvalues $\\tau_1$ and $\\tau_2$ are calculated from the depth-averaged (2D) stress tensor $\\tau_{\\rm ij}$ as follows. Given the stress tensor components $\\tau_{\\rm xx}$, $\\tau_{\\rm yy}$ and $\\tau_{\\rm xy}$, we can solve for the real roots $\\lambda$ of the tensor from the quadratic equation: a \\lambda^2 + b \\lambda + c = 0 where a = 1.0 \\\\ b = -(\\tau_{\\rm xx} + \\tau_{\\rm yy}) \\\\ c = \\tau_{\\rm xx}*\\tau_{\\rm yy} - \\tau_{\\rm xy}^2 glissade_velo_higher.F90: tau_xz(k,i,j) = tau_xz(k,i,j) + efvs_qp * du_dz ! 2 * efvs * eps_xz tau_yz(k,i,j) = tau_yz(k,i,j) + efvs_qp * dv_dz ! 2 * efvs * eps_yz tau_xx(k,i,j) = tau_xx(k,i,j) + 2.d0 * efvs_qp * du_dx ! 2 * efvs * eps_xx tau_yy(k,i,j) = tau_yy(k,i,j) + 2.d0 * efvs_qp * dv_dy ! 2 * efvs * eps_yy tau_xy(k,i,j) = tau_xy(k,i,j) + efvs_qp * (dv_dx + du_dy) ! 2 * efvs * eps_xy","title":"Lipscomb et al. (2019)"},{"location":"notes/#vertical-velocity","text":"w = u_b \\frac{\\partial b}{\\partial x} + v_b \\frac{\\partial b}{\\partial y} - \\int_b^z \\left( \\frac{\\partial u}{\\partial x} + \\frac{\\partial v}{\\partial y} \\right) dz'","title":"Vertical velocity"},{"location":"notes/#ice-margin-calving-rates-mass-conservation","text":"ajr, 2021-06-22 Through v1.42 , ice margins were not fully consistently treated in Yelmo. This has been thoroughly revised. Now the following should be true: The variable f_ice contains information of the ice area fraction of a grid cell. If f_ice=0 , no ice is present, if f_ice=1 , the cell is fully ice covered, and for a fractional value, this cell is designated an ice margin point with partial ice cover. To determine f_ice , we need to calculate the \"effective ice thickness\" of a grid point. For floating cells at the margin, the effective ice thickness is equivalent to either the ice thickness or the minimum ice thickness of the neighboring cell, whichever is larger. For grounded cells, the effective ice thickness must at least be that of 1/2 of the minimum ice thickness of a neighboring cell. With effective ice thickness known, f_ice = H_ice / H_eff . Any grid cell with fractional ice cover 0<f_ice<1 is designated dynamically inactive on its outer borders (borders with ice-free points). Thus before a new cell can be populated with ice, first the fractional cell must be filled to reach f_ice=1 . Velocity and the ssa solver now explicitly only treat cells with f_ice=1 . The dynamic-inactive borders are also enforced explicitly in the mass_conservation routine for safety. The calving rate is diagnosed as a lateral flux assuming a thickness of H_eff , but then is converted to a horizontal mass balance component applied to the whole cell. Additionally, it is possible to ensure 'residual calving' is applied to the upstream grid point of a margin cell, if the calving rate is large enough. This is done via the new routine calc_calving_residual . In the case of the simple and flux methods, applying full residual calving rates causes far too much calving. Rather a small amount of residual calving is applied to conservatively diminish the dynamic status of the upstream cell. The latter was implemented following CISM. Other important changes Major bug fix with thermodynamics and vertical velocity. The vertical velocity correction that was being applied to account for the sigma coordinates was incorrect. A correction must be applied to get the vertical velocity itself. Then another correction must be applied when calculating the vertical advection in the thermodynamics routine. Now this is hopefully done correctly. EISMINT EXPA and EXPF appear to work well. This may hopefully prove crucial for Javi's advance/retreat issues in Antarctica. Modified staggering of 3D viscosity to be done on horizontal ab-nodes, then averaged to the center. This follows a 'quadrature' approach and appears to be more rigorously close to actually integrating over the area. It's not clear how this might affect stability of ice streams (i.e., Daniel's results). Two-step mass balance with updates to f_ice in between, with more explicit tracking of all mass changes. Now a new variable mb_resid holds any threshold changes applied at the end of the mass balance update. I haven't checked in detail, but I hope all mass changes are now accounted for explicitly in the model. To do... vm-l19 calving method seems to be too sensitive. A reasonable coefficient value is kt=0.0001 instead of the value used by Lipscomb et al. (2019) of kt=0.0025 . Reducing where calv_resid is redistributed only to cells with the same ice thickness reduces this sensitivity. Needs checking. Threshold methods ( simple , flux , flux-grisli ) are not sensitive enough. Need to test how to apply calv_resid more robustly, or find another solution.","title":"Ice margin, calving rates, mass conservation"},{"location":"optimization/","text":"Basal friction optimization A simple optimization program has developed that attempts to optimize the basal friction field applied in Yelmo so that the errors between simulated and observed ice thickness are minimized. Program: tests/yelmo_opt.f90 To compile: make opt To run: ./runylmo -s -e opt -o output/test -n par/yelmo_Antarctica_opt.nml The program consists of the following steps: 1. Spin-up a steady-state ice sheet with constant forcing and fixed topography. For this step, the restart parameter should be set to yelmo.restart='none' , to ensure that the spin-up is performed with the current parameters. Currently, the program is hard-coded to spin-up the ice sheet for 20 kyr using SIA only, followed by another 10 kyr using the solver of choice, as seen in the following lines of code: call yelmo_update_equil_external(yelmo1,hyd1,cf_ref,time_init,time_tot=20e3,topo_fixed=.TRUE.,dt=5.0,ssa_vel_max=0.0) call yelmo_update_equil_external(yelmo1,hyd1,cf_ref,time_init,time_tot=10e3, topo_fixed=.TRUE.,dt=1.0,ssa_vel_max=5000.0) Note that this spin-up is obtained with a fixed topography set to the present-day observed fields ( H_ice , z_bed ). After the spin-up finishes, a restart file is written in the output directory with the name yelmo_restart.nc . The simulation will terminate at this point. 2. Optimization The restart file from Step 1 should be saved somewhere convenient for the model (like in the input folder). Then the restart parameter should be set to that location yelmo.restart='PATH_TO_RESTART.nc' . This will ensure that the spin-up step is skipped, and instead the program will start directly with the optimization iterations. The optimization method follows Pollard and DeConto (2012), in that the basal friction coefficient is scaled as a function of the error in elevation. Here we do not modify beta directly, however, we assume that beta = cf_ref * lambda_bed * N_eff * f(u) . lambda_bed , N_eff and f(u) are all controlled by parameter choices in the .nml file like normal. Thus we are left with a unitless field cf_ref , which for any given friction law varies within the range of about [0:1]. When cf_ref=1.0 , sliding will diminish to near zero, and cf_ref~0.0 (near, but not zero) will give fast sliding. This gives a convenient range for optimization. Parameters that control the total run time are hard coded: qmax : number of total iterations to run, where qmax-1 is the number of optimization steps, during which cf_ref is updated, and the last step is a steady-state run with cf_ref held constant. time_iter : time to run the model for each iteration before updating cf_ref . time_steady : Time to run the model to steady state with cf_ref held constant (last iteration step). So, the program runs for, e.g., time_iter=500 years with a given initial field of cf_ref (with C_bed and beta updating every time step to follow changes in u/v and N_eff ). At the end of time_iter , the error in ice thickness is determined and used to update cf_ref via the function update_cf_ref_thickness_simple . The model is again run for time_iter years and the process is repeated. Two important parameters control the optimization process: tau and H_scale . The optimization works best when the ice shelves are relaxed to the reference (observed) ice thickness in the beginning of the simulation, and then gradually allowed to freely evolve. tau is the time scale of relaxation, which is applied in Yelmo as yelmo1%tpo%par%topo_rel_tau . A lower value of tau means that the ice shelves are more tightly held to the observed thickness. Likewise, H_scale controls the scaling of the ice thickness error, which determines how to modify cf_ref at each iteration. A higher value of H_scale means that changes to cf_ref will be applied more slowly. These parameters are designed to change over time with the simulation. tau is set to rel_tau1 from the start of the simulation until rel_time1 . Between rel_time1 and rel_time2 , tau is linearly scaled from the value of rel_tau1 to rel_tau2 . Or, if rel_q > 1 , then the scaling is non-linear with an exponent of rel_q (this helps maintain small values of tau longer which seems to help keep errors low). Once rel_time2 is reached, relaxation in the model is disabled, and the ice shelves are allowed to freely evolve. Analogously, H_scale is modified the same way: it is constant at the value of scale_H1 until scale_time1 , linearly scaled between scale_time1 and scale_time2 , and then constant thereafter at the value of scale_H2 . Increasing the value of H_scale over time helps to avoid oscillations in the optimization procedure as cf_ref approaches the best fit. Finally, after qmax-1 iterations or time=(qmax-1)*time_iter , cf_ref is held constant, and the simulation runs for time_steady years to equilibrate the model with the current conditions. This step minimizes drift in the final result and confirms that the optimized cf_ref field works well.","title":"Basal friction optimization"},{"location":"optimization/#basal-friction-optimization","text":"A simple optimization program has developed that attempts to optimize the basal friction field applied in Yelmo so that the errors between simulated and observed ice thickness are minimized. Program: tests/yelmo_opt.f90 To compile: make opt To run: ./runylmo -s -e opt -o output/test -n par/yelmo_Antarctica_opt.nml The program consists of the following steps:","title":"Basal friction optimization"},{"location":"optimization/#1-spin-up-a-steady-state-ice-sheet-with-constant-forcing-and-fixed-topography","text":"For this step, the restart parameter should be set to yelmo.restart='none' , to ensure that the spin-up is performed with the current parameters. Currently, the program is hard-coded to spin-up the ice sheet for 20 kyr using SIA only, followed by another 10 kyr using the solver of choice, as seen in the following lines of code: call yelmo_update_equil_external(yelmo1,hyd1,cf_ref,time_init,time_tot=20e3,topo_fixed=.TRUE.,dt=5.0,ssa_vel_max=0.0) call yelmo_update_equil_external(yelmo1,hyd1,cf_ref,time_init,time_tot=10e3, topo_fixed=.TRUE.,dt=1.0,ssa_vel_max=5000.0) Note that this spin-up is obtained with a fixed topography set to the present-day observed fields ( H_ice , z_bed ). After the spin-up finishes, a restart file is written in the output directory with the name yelmo_restart.nc . The simulation will terminate at this point.","title":"1. Spin-up a steady-state ice sheet with constant forcing and fixed topography."},{"location":"optimization/#2-optimization","text":"The restart file from Step 1 should be saved somewhere convenient for the model (like in the input folder). Then the restart parameter should be set to that location yelmo.restart='PATH_TO_RESTART.nc' . This will ensure that the spin-up step is skipped, and instead the program will start directly with the optimization iterations. The optimization method follows Pollard and DeConto (2012), in that the basal friction coefficient is scaled as a function of the error in elevation. Here we do not modify beta directly, however, we assume that beta = cf_ref * lambda_bed * N_eff * f(u) . lambda_bed , N_eff and f(u) are all controlled by parameter choices in the .nml file like normal. Thus we are left with a unitless field cf_ref , which for any given friction law varies within the range of about [0:1]. When cf_ref=1.0 , sliding will diminish to near zero, and cf_ref~0.0 (near, but not zero) will give fast sliding. This gives a convenient range for optimization. Parameters that control the total run time are hard coded: qmax : number of total iterations to run, where qmax-1 is the number of optimization steps, during which cf_ref is updated, and the last step is a steady-state run with cf_ref held constant. time_iter : time to run the model for each iteration before updating cf_ref . time_steady : Time to run the model to steady state with cf_ref held constant (last iteration step). So, the program runs for, e.g., time_iter=500 years with a given initial field of cf_ref (with C_bed and beta updating every time step to follow changes in u/v and N_eff ). At the end of time_iter , the error in ice thickness is determined and used to update cf_ref via the function update_cf_ref_thickness_simple . The model is again run for time_iter years and the process is repeated. Two important parameters control the optimization process: tau and H_scale . The optimization works best when the ice shelves are relaxed to the reference (observed) ice thickness in the beginning of the simulation, and then gradually allowed to freely evolve. tau is the time scale of relaxation, which is applied in Yelmo as yelmo1%tpo%par%topo_rel_tau . A lower value of tau means that the ice shelves are more tightly held to the observed thickness. Likewise, H_scale controls the scaling of the ice thickness error, which determines how to modify cf_ref at each iteration. A higher value of H_scale means that changes to cf_ref will be applied more slowly. These parameters are designed to change over time with the simulation. tau is set to rel_tau1 from the start of the simulation until rel_time1 . Between rel_time1 and rel_time2 , tau is linearly scaled from the value of rel_tau1 to rel_tau2 . Or, if rel_q > 1 , then the scaling is non-linear with an exponent of rel_q (this helps maintain small values of tau longer which seems to help keep errors low). Once rel_time2 is reached, relaxation in the model is disabled, and the ice shelves are allowed to freely evolve. Analogously, H_scale is modified the same way: it is constant at the value of scale_H1 until scale_time1 , linearly scaled between scale_time1 and scale_time2 , and then constant thereafter at the value of scale_H2 . Increasing the value of H_scale over time helps to avoid oscillations in the optimization procedure as cf_ref approaches the best fit. Finally, after qmax-1 iterations or time=(qmax-1)*time_iter , cf_ref is held constant, and the simulation runs for time_steady years to equilibrate the model with the current conditions. This step minimizes drift in the final result and confirms that the optimized cf_ref field works well.","title":"2. Optimization"},{"location":"parameters/","text":"Parameters Here important parameter choices pertinent to running Yelmo will be documented. Each section will outline a specific parameter or set of related parameters. The author of each section and the date last updated will apear in the heading, to maintain traceability in the documentation (since code usually changes over time). To do","title":"Parameters"},{"location":"parameters/#parameters","text":"Here important parameter choices pertinent to running Yelmo will be documented. Each section will outline a specific parameter or set of related parameters. The author of each section and the date last updated will apear in the heading, to maintain traceability in the documentation (since code usually changes over time).","title":"Parameters"},{"location":"parameters/#to-do","text":"","title":"To do"},{"location":"remapping/","text":"Remapping Yelmo runs on a Cartesian (x/y) grid. Often input data comes in many formats, global lat/lon grids, projections and sets of points. It is important to have robust remapping tools. Typically for a given domain, we define a Polar Stereographic projection to be able to convert lat/lon data points onto a Cartesian plane. For Antarctica, for example, the standard projection has the following parameters: int polar_stereographic ; polar_stereographic:grid_mapping_name = \"polar_stereographic\" ; polar_stereographic:straight_vertical_longitude_from_pole = 0. ; polar_stereographic:latitude_of_projection_origin = -71. ; polar_stereographic:angle_of_oblique_tangent = 19. ; polar_stereographic:scale_factor_at_projection_origin = 1. ; polar_stereographic:false_easting = 0. ; polar_stereographic:false_northing = 0. ; Naming files For grids used by Yelmo, we generally use an abbreviation for the domain name followed by the resolution. So for Antarctica, we could have the grids ANT-32KM or ANT-16KM for a 32km or 16km grid, respectively. Data that have been projected onto these grids are saved with the grid name as a prefix followed by a general name that specifies the type of data, e.g., CLIM or TOPO , finally followed by more descriptive information about the specific dataset IPSL-14Ma or IPSL-PD-CTRL . For example, the latest topopgraphy dataset we use is called the RTopo2.0.1 dataset, so this is processed into a file called ANT-32KM_TOPO-RTOPO-2.0.1.nc . Fields Yelmo needs To drive Yelmo with boundary conditions derived from a climate model, it needs the following fields to be defined on the Polar Stereographic grid: Climatological mean near-surface air temperature [monthly] Climatological mean precipitation [monthly] Surface elevation Sea level Ice thickness Climatological mean 3D ocean temperature [annual] Climatological mean 3D ocean salinity [annual] Oceanic bathymetry Likely these would be processed into two or more separate files, e.g., one for climate CLIM variables and another for ocean OCN variables. Preprocessing data using cdo As a first step, the Climate Data Operators cdo package is great for most preprocessing steps. It can handle averaging data over time and space, merging data files, extracting individual variables etc. See the extensive documentation and examples online. For example, it is possible to use the command cdo selvar to extract specific variables from a file: cdo selvar,t2m,precip diane_C14Ma_1_5PAL_SE_4750_4849_1M_histmth.nc ipsl_tmp1.nc If you have several variables in individual files, you can then conveniently merge them into one file usine merge (it's better if they have the same shape): # Extract t2m to a temporary file cdo selvar,t2m diane_C14Ma_1_5PAL_SE_4750_4849_1M_histmth.nc ipsl_tmp1.nc # Extract precip to a temporary file cdo selvar,precip diane_C14Ma_1_5PAL_SE_4750_4849_1M_histmth.nc ipsl_tmp2.nc # Merge the two individual variable files into one convenient file cdo merge ipsl_tmp1.nc ipsl_tmp2.nc ipsl_tmp3.nc There are many other useful commands, particularly for getting monthly means cdo monmean ... and other statistics. Resources: CDO Documentation page: https://code.mpimet.mpg.de/projects/cdo/wiki/Cdo#Documentation CDO User guide: https://code.mpimet.mpg.de/projects/cdo/embedded/cdo.pdf CDO Reference card: https://code.mpimet.mpg.de/projects/cdo/embedded/cdo_refcard.pdf Using cdo for remapping To remap a data file from lat/lon coordinates to our projection, cdo needs a grid description file that describes the target Polar Stereographic projection grid. For example, for a 32km resolution domain, we would use the following file named grid_ANT-32KM.txt : gridtype = projection gridsize = 36481 xsize = 191 ysize = 191 xname = xc xunits = km yname = yc yunits = km xfirst = -3040.000000 xinc = 32.000000 yfirst = -3040.000000 yinc = 32.000000 grid_mapping = crs grid_mapping_name = polar_stereographic straight_vertical_longitude_from_pole = 0.000 latitude_of_projection_origin = -90.000 standard_parallel = -71.000 false_easting = 0.000 false_northing = 0.000 semi_major_axis = 6378137.000 inverse_flattening = 298.25722356 With this file defined, it's easy to perform projections using the cdo remap* commands. To perform a bicubic interpolation, call: cdo remapbic,grid_ANT-32KM.txt diane_C14Ma_1_5PAL_SE_4750_4849_1M_histmth.nc ANT-32KM_test-bic.nc Here, remapbic specifies bicubic interpolation and grid_ANT-32KM.txt defines the target grid as above. Then the source dataset is specified and the desired output file ANT-32KM_test.nc . To perform conservative interpolation, replace remapbic with remapcon : cdo remapcon,grid_ANT-32KM.txt diane_C14Ma_1_5PAL_SE_4750_4849_1M_histmth.nc ANT-32KM_test-con.nc Conservative interpolation is generally preferred, especially when going from a high resolution to a lower resolution, as it avoids unwanted interpolation artifacts and conserves the quantity being remapped. However, from low resolution to high resolution, conservative interpolation can result in more \"blocky\" fields with abrupt changes in values. Thus, in this case, bicubic interpolation, or conservative interpolation with additional Gaussian smoothing is better. The latter is not supported by cdo , but can be acheived with other tools. One option for processing may be a conservative remapping, following by a smoothing step: cdo remapcon,grid_ANT-32KM.txt diane_C14Ma_1_5PAL_SE_4750_4849_1M_histmth.nc ANT-32KM_test-con.nc cdo smooth,radius=128km ANT-32KM_test-con.nc ANT-32KM_test-con-smooth.nc The smoothing radius should be chosen such that it is the smallest value possible that removes blocky artifacts from the field. Summary It can be tedious to process data from a climate model into the right format to drive Yelmo. Tools like cdo help to reduce this burden. Other tools like NetCDF Operator NCO and today numerous Python-based libraries and tools can also be used. It is best to define a script or program with all the processing steps clearly defined. That way, when new data becomes available from the same model, it is easy to process it systematically (and reproducibly) in the same way without any trouble.","title":"Remapping"},{"location":"remapping/#remapping","text":"Yelmo runs on a Cartesian (x/y) grid. Often input data comes in many formats, global lat/lon grids, projections and sets of points. It is important to have robust remapping tools. Typically for a given domain, we define a Polar Stereographic projection to be able to convert lat/lon data points onto a Cartesian plane. For Antarctica, for example, the standard projection has the following parameters: int polar_stereographic ; polar_stereographic:grid_mapping_name = \"polar_stereographic\" ; polar_stereographic:straight_vertical_longitude_from_pole = 0. ; polar_stereographic:latitude_of_projection_origin = -71. ; polar_stereographic:angle_of_oblique_tangent = 19. ; polar_stereographic:scale_factor_at_projection_origin = 1. ; polar_stereographic:false_easting = 0. ; polar_stereographic:false_northing = 0. ;","title":"Remapping"},{"location":"remapping/#naming-files","text":"For grids used by Yelmo, we generally use an abbreviation for the domain name followed by the resolution. So for Antarctica, we could have the grids ANT-32KM or ANT-16KM for a 32km or 16km grid, respectively. Data that have been projected onto these grids are saved with the grid name as a prefix followed by a general name that specifies the type of data, e.g., CLIM or TOPO , finally followed by more descriptive information about the specific dataset IPSL-14Ma or IPSL-PD-CTRL . For example, the latest topopgraphy dataset we use is called the RTopo2.0.1 dataset, so this is processed into a file called ANT-32KM_TOPO-RTOPO-2.0.1.nc .","title":"Naming files"},{"location":"remapping/#fields-yelmo-needs","text":"To drive Yelmo with boundary conditions derived from a climate model, it needs the following fields to be defined on the Polar Stereographic grid: Climatological mean near-surface air temperature [monthly] Climatological mean precipitation [monthly] Surface elevation Sea level Ice thickness Climatological mean 3D ocean temperature [annual] Climatological mean 3D ocean salinity [annual] Oceanic bathymetry Likely these would be processed into two or more separate files, e.g., one for climate CLIM variables and another for ocean OCN variables.","title":"Fields Yelmo needs"},{"location":"remapping/#preprocessing-data-using-cdo","text":"As a first step, the Climate Data Operators cdo package is great for most preprocessing steps. It can handle averaging data over time and space, merging data files, extracting individual variables etc. See the extensive documentation and examples online. For example, it is possible to use the command cdo selvar to extract specific variables from a file: cdo selvar,t2m,precip diane_C14Ma_1_5PAL_SE_4750_4849_1M_histmth.nc ipsl_tmp1.nc If you have several variables in individual files, you can then conveniently merge them into one file usine merge (it's better if they have the same shape): # Extract t2m to a temporary file cdo selvar,t2m diane_C14Ma_1_5PAL_SE_4750_4849_1M_histmth.nc ipsl_tmp1.nc # Extract precip to a temporary file cdo selvar,precip diane_C14Ma_1_5PAL_SE_4750_4849_1M_histmth.nc ipsl_tmp2.nc # Merge the two individual variable files into one convenient file cdo merge ipsl_tmp1.nc ipsl_tmp2.nc ipsl_tmp3.nc There are many other useful commands, particularly for getting monthly means cdo monmean ... and other statistics. Resources: CDO Documentation page: https://code.mpimet.mpg.de/projects/cdo/wiki/Cdo#Documentation CDO User guide: https://code.mpimet.mpg.de/projects/cdo/embedded/cdo.pdf CDO Reference card: https://code.mpimet.mpg.de/projects/cdo/embedded/cdo_refcard.pdf","title":"Preprocessing data using cdo"},{"location":"remapping/#using-cdo-for-remapping","text":"To remap a data file from lat/lon coordinates to our projection, cdo needs a grid description file that describes the target Polar Stereographic projection grid. For example, for a 32km resolution domain, we would use the following file named grid_ANT-32KM.txt : gridtype = projection gridsize = 36481 xsize = 191 ysize = 191 xname = xc xunits = km yname = yc yunits = km xfirst = -3040.000000 xinc = 32.000000 yfirst = -3040.000000 yinc = 32.000000 grid_mapping = crs grid_mapping_name = polar_stereographic straight_vertical_longitude_from_pole = 0.000 latitude_of_projection_origin = -90.000 standard_parallel = -71.000 false_easting = 0.000 false_northing = 0.000 semi_major_axis = 6378137.000 inverse_flattening = 298.25722356 With this file defined, it's easy to perform projections using the cdo remap* commands. To perform a bicubic interpolation, call: cdo remapbic,grid_ANT-32KM.txt diane_C14Ma_1_5PAL_SE_4750_4849_1M_histmth.nc ANT-32KM_test-bic.nc Here, remapbic specifies bicubic interpolation and grid_ANT-32KM.txt defines the target grid as above. Then the source dataset is specified and the desired output file ANT-32KM_test.nc . To perform conservative interpolation, replace remapbic with remapcon : cdo remapcon,grid_ANT-32KM.txt diane_C14Ma_1_5PAL_SE_4750_4849_1M_histmth.nc ANT-32KM_test-con.nc Conservative interpolation is generally preferred, especially when going from a high resolution to a lower resolution, as it avoids unwanted interpolation artifacts and conserves the quantity being remapped. However, from low resolution to high resolution, conservative interpolation can result in more \"blocky\" fields with abrupt changes in values. Thus, in this case, bicubic interpolation, or conservative interpolation with additional Gaussian smoothing is better. The latter is not supported by cdo , but can be acheived with other tools. One option for processing may be a conservative remapping, following by a smoothing step: cdo remapcon,grid_ANT-32KM.txt diane_C14Ma_1_5PAL_SE_4750_4849_1M_histmth.nc ANT-32KM_test-con.nc cdo smooth,radius=128km ANT-32KM_test-con.nc ANT-32KM_test-con-smooth.nc The smoothing radius should be chosen such that it is the smallest value possible that removes blocky artifacts from the field.","title":"Using cdo for remapping"},{"location":"remapping/#summary","text":"It can be tedious to process data from a climate model into the right format to drive Yelmo. Tools like cdo help to reduce this burden. Other tools like NetCDF Operator NCO and today numerous Python-based libraries and tools can also be used. It is best to define a script or program with all the processing steps clearly defined. That way, when new data becomes available from the same model, it is easy to process it systematically (and reproducibly) in the same way without any trouble.","title":"Summary"},{"location":"running-hysteresis/","text":"Running hysteresis experiments for Antarctica For now, we will: Use optimized basal friction. Spinup with a constant present-day climate based on the ISMIP6 protocol. To run yelmox with this setup, we need the hyst-2021 branches: cd yelmox git checkout hyst-2021 cd yelmo git checkout hyst-2021 # Reconfigure python3 config.py config/snowball_gfortran cd .. python3 config.py config/snowball_gfortran # If not done already, link to ice_data ln -s /media/Data/ice_data ice_data We will run with the ISMIP6 standard YelmoX program, so compile: make clean make yelmox_ismip6 The hysteresis runs can be done in two steps: 1. First, generate a spun-up simulation with optimized basal friction. 2. Restart from the optimized, spun-up state and continue with transient forcing from the hysteresis module. Step 1: spinup The spinup simulation runs for 30.000 years, by default. For the first opt_L21.rel_time1=5e3 years, the shelves and grounding line are relaxed (tightly) to the present-day reference state, while the optimization of the basal friction field cf_ref is active. Next between opt_L21.rel_time1=5e3 kyr and opt_L21.rel_time2=10e3 years, the relaxation timescale is slowly increased from opt_L21.rel_tau1=10 yrs to opt_L21.rel_tau2=1000 yrs, to slowly allow the ice sheet more freedom to adjust its state. Basal optimization is further optimized during this time period. After opt_L21.rel_time2=10e3 years, the relation is disabled and the ice sheet if fully prognostic. The simulation is further run until the end with continual optimization adjustments to cf_ref , although these are usually minor after the initial spinup period. To run a spinup simulation as above, use the following command: # First run spinup simulation # (steady-state present day boundary conditions) ./runylmox -r -e ismip6 -n par/yelmo_ismip6_Antarctica.nml -o output/hyst/spinup01 -p ctrl.run_step=\"spinup_ismip6\" opt_L21.cf_min=1e-3 ytopo.kt=0.10e-2 tf_corr_ant.ronne=0.25 tf_corr_ant.ross=0.2 tf_corr_ant.pine=-0.5 Or an ensemble to test different parameters too: fldr=output/hyst/spinup02 jobrun ./runylmox -r -e ismip6 -n par/yelmo_ismip6_Antarctica.nml -- -o ${fldr} -p ctrl.run_step=\"spinup_ismip6\" opt_L21.cf_min=1e-3 ytopo.kt=0.10e-2,0.20e-2,0.30e-2,0.40e-2 tf_corr_ant.ronne=0.0,0.25 tf_corr_ant.ross=0.0,0.2 tf_corr_ant.pine=-0.5,0.0 To make the spinup run for a longer time, like 50 kyr, set ctrl.time_end=50e3 . If you already have a spinup simulation available, you can skip that step. Alternatively, you can specify one that is ready on snowball : yelmo.restart=/home/robinson/abumip-2021/yelmox/output/ismip6/spinup11/1/yelmo_restart.nc Step 2: transient simulations To run transient simulations the run_step should be specified as ctrl.run_step=\"hysteresis_proj\" . Typically model parameters should be defined to be equivalent to those used by the restart simulation. The time control parameters of the simulation are defined in the parameter section &hysteresis_proj . Parameters associated with the hysteresis module can be changed in the &hyster section. To be consistent with the restart file above, the following reference parameter values should be set in the parameter file (or at the command line, if used as part of the ensemble): ctrl.run_step=\"hysteresis_proj\" tf_cor.name=\"dT_nl\" marine_shelf.gamma_quad_nl=14500 yelmo.restart=/home/robinson/abumip-2021/yelmox/output/ismip6/spinup11/1/yelmo_restart.nc tf_corr_ant.ronne=0.25 tf_corr_ant.ross=0.2 tf_corr_ant.pine=-0.5 # For setting output frequency hysteresis_proj.dt2D_out=5e3 hysteresis.dt2D_small_out=100 Example transient simulation of hysteresis_proj.time_end=500 years, with ramp forcing via the hyster module with 100 years of constant forcing, followed by a ramp over 250 years from an anomaly of 0 degC to 5 degC: ./runylmox -r -e ismip6 -n par/yelmo_ismip6_Antarctica.nml -o output/hyst/test1 -p ytopo.kt=0.001 \\ hyster.method=\"ramp\" hyster.dt_init=100 hyster.dt_ramp=250 hyster.f_min=0 hyster.f_max=5 Example transient simulation using Adaptive Quasi-Equilibrium Forcing (AQEF) with no lead-in time: ./runylmox -r -e ismip6 -n par/yelmo_ismip6_Antarctica.nml -o output/hyst/test2 -p ytopo.kt=0.001 \\ hyster.method=\"PI42\" hyster.dt_init=0 hyster.f_min=0 hyster.f_max=5 Or simply further constant forcing of a control run by setting hyster.method=\"const\" . You can add white noise (Normal distribution) to your forcing by setting the standard deviation greater than zero: hyster.sigma=1.0 .","title":"Running hysteresis experiments for Antarctica"},{"location":"running-hysteresis/#running-hysteresis-experiments-for-antarctica","text":"For now, we will: Use optimized basal friction. Spinup with a constant present-day climate based on the ISMIP6 protocol. To run yelmox with this setup, we need the hyst-2021 branches: cd yelmox git checkout hyst-2021 cd yelmo git checkout hyst-2021 # Reconfigure python3 config.py config/snowball_gfortran cd .. python3 config.py config/snowball_gfortran # If not done already, link to ice_data ln -s /media/Data/ice_data ice_data We will run with the ISMIP6 standard YelmoX program, so compile: make clean make yelmox_ismip6 The hysteresis runs can be done in two steps: 1. First, generate a spun-up simulation with optimized basal friction. 2. Restart from the optimized, spun-up state and continue with transient forcing from the hysteresis module.","title":"Running hysteresis experiments for Antarctica"},{"location":"running-hysteresis/#step-1-spinup","text":"The spinup simulation runs for 30.000 years, by default. For the first opt_L21.rel_time1=5e3 years, the shelves and grounding line are relaxed (tightly) to the present-day reference state, while the optimization of the basal friction field cf_ref is active. Next between opt_L21.rel_time1=5e3 kyr and opt_L21.rel_time2=10e3 years, the relaxation timescale is slowly increased from opt_L21.rel_tau1=10 yrs to opt_L21.rel_tau2=1000 yrs, to slowly allow the ice sheet more freedom to adjust its state. Basal optimization is further optimized during this time period. After opt_L21.rel_time2=10e3 years, the relation is disabled and the ice sheet if fully prognostic. The simulation is further run until the end with continual optimization adjustments to cf_ref , although these are usually minor after the initial spinup period. To run a spinup simulation as above, use the following command: # First run spinup simulation # (steady-state present day boundary conditions) ./runylmox -r -e ismip6 -n par/yelmo_ismip6_Antarctica.nml -o output/hyst/spinup01 -p ctrl.run_step=\"spinup_ismip6\" opt_L21.cf_min=1e-3 ytopo.kt=0.10e-2 tf_corr_ant.ronne=0.25 tf_corr_ant.ross=0.2 tf_corr_ant.pine=-0.5 Or an ensemble to test different parameters too: fldr=output/hyst/spinup02 jobrun ./runylmox -r -e ismip6 -n par/yelmo_ismip6_Antarctica.nml -- -o ${fldr} -p ctrl.run_step=\"spinup_ismip6\" opt_L21.cf_min=1e-3 ytopo.kt=0.10e-2,0.20e-2,0.30e-2,0.40e-2 tf_corr_ant.ronne=0.0,0.25 tf_corr_ant.ross=0.0,0.2 tf_corr_ant.pine=-0.5,0.0 To make the spinup run for a longer time, like 50 kyr, set ctrl.time_end=50e3 . If you already have a spinup simulation available, you can skip that step. Alternatively, you can specify one that is ready on snowball : yelmo.restart=/home/robinson/abumip-2021/yelmox/output/ismip6/spinup11/1/yelmo_restart.nc","title":"Step 1: spinup"},{"location":"running-hysteresis/#step-2-transient-simulations","text":"To run transient simulations the run_step should be specified as ctrl.run_step=\"hysteresis_proj\" . Typically model parameters should be defined to be equivalent to those used by the restart simulation. The time control parameters of the simulation are defined in the parameter section &hysteresis_proj . Parameters associated with the hysteresis module can be changed in the &hyster section. To be consistent with the restart file above, the following reference parameter values should be set in the parameter file (or at the command line, if used as part of the ensemble): ctrl.run_step=\"hysteresis_proj\" tf_cor.name=\"dT_nl\" marine_shelf.gamma_quad_nl=14500 yelmo.restart=/home/robinson/abumip-2021/yelmox/output/ismip6/spinup11/1/yelmo_restart.nc tf_corr_ant.ronne=0.25 tf_corr_ant.ross=0.2 tf_corr_ant.pine=-0.5 # For setting output frequency hysteresis_proj.dt2D_out=5e3 hysteresis.dt2D_small_out=100 Example transient simulation of hysteresis_proj.time_end=500 years, with ramp forcing via the hyster module with 100 years of constant forcing, followed by a ramp over 250 years from an anomaly of 0 degC to 5 degC: ./runylmox -r -e ismip6 -n par/yelmo_ismip6_Antarctica.nml -o output/hyst/test1 -p ytopo.kt=0.001 \\ hyster.method=\"ramp\" hyster.dt_init=100 hyster.dt_ramp=250 hyster.f_min=0 hyster.f_max=5 Example transient simulation using Adaptive Quasi-Equilibrium Forcing (AQEF) with no lead-in time: ./runylmox -r -e ismip6 -n par/yelmo_ismip6_Antarctica.nml -o output/hyst/test2 -p ytopo.kt=0.001 \\ hyster.method=\"PI42\" hyster.dt_init=0 hyster.f_min=0 hyster.f_max=5 Or simply further constant forcing of a control run by setting hyster.method=\"const\" . You can add white noise (Normal distribution) to your forcing by setting the standard deviation greater than zero: hyster.sigma=1.0 .","title":"Step 2: transient simulations"},{"location":"running-with-yelmox/","text":"Running with YelmoX YelmoX is a separate repository that is designed to provide supplementary libraries and programs that allow running ice-sheet simulations with realistic boundary (e.g., climate and ocean) forcing and interactions (e.g., isostatic rebound). Here you can find the basic information and steps needed to get YelmoX running. Super-quick start A summary of commands to get started is given below. For more detailed information see subsequent sections. # Before doing anything, make sure dependencies are installed (Lis, NetCDF, runner) ########################## # Clone repository git clone https://github.com/palma-ice/yelmox.git git clone git@github.com:palma-ice/yelmox.git # or via ssh # Clone yelmo into a sub-directory too cd yelmox git clone https://github.com/palma-ice/yelmo.git git clone git@github.com:palma-ice/yelmo.git # or, via ssh # Check out your yelmox branch of interest (optional) git checkout my-branch # for an existing branch git checkout -b my-new-branch # or, to create a new one # Do the same for yelmo branch if needed, and return to yelmox directory cd yelmo git checkout my-branch cd .. # Enter yelmo directory and configure it for compiling cd yelmo python3 config.py config/snowball_gfortran # or the right config file for your system # Return to yelmox directory and configure it for compiling cd .. python3 config.py config/snowball_gfortran # or the right config file for your system # Now, compile the default program make clean make yelmox # Link to `ice_data` repository wherever you have it saved on your system ln -s path_to/ice_data # Copy the runylmox config file to the main directory cp config/runylmox.js ./ # Run a test simulation of Antarctica for 1000 yrs ./runylmox -r -e yelmox -n par/yelmo_Antarctica.nml -o output/ant-test -p ctrl.time_end=1e3 Standard YelmoX simulations To run YelmoX, by default we use the program yelmox.f90 . This program currently makes use of snapclim for the climatic forcing and smbpal for the snowpack and surface mass balance calculations. ISMIP6 simulations First make sure your distribution of yelmox and yelmo are up to date. cd yelmo git pull cd .. # In the main yelmox directory, change to the branch 'tfm2021': git pull git checkout tfm2021 # From main directory of yelmox, also reconfigure to adopt all changes: python3 config.py config/snowball_gfortran cp config/runylmox.js ./ Now compile as normal, but with the yelmox_ismip6 program: make clean make yelmox_ismip6 That's it, you are now ready to run some ISMIP6 simulations. If you need to run a spinup simulation that also optimizes basal friction, run the following command: # First run spinup simulation # (steady-state present day boundary conditions) ./runylmox -r -e ismip6 -n par/yelmo_ismip6_Antarctica.nml -o output/ismip6/spinup_opt11 -p ctrl.run_step=\"spinup_ismip6\" opt_L21.cf_min=1e-3 ytopo.kt=0.10e-2 tf_corr_ant.ronne=0.0 tf_corr_ant.ross=0.0 Or an ensemble to test different parameters too: fldr=tmp/ismip6/spinup10 jobrun ./runylmox -s -q short -w 10 -e ismip6 -n par/yelmo_ismip6_Antarctica.nml -- -o ${fldr} -p ctrl.run_step=\"spinup_ismip6\" opt_L21.cf_min=1e-3 ytopo.kt=0.10e-2,0.20e-2,0.30e-2,0.40e-2 tf_corr_ant.ronne=0.0,0.25 tf_corr_ant.ross=0.0,0.2 If you already have a spinup simulation available, you can skip that step. You can also copy one from here: mkdir output/ismip6 cp -r /home/robinson/yelmox/output/ismip6/spinup_opt11 output/ismip6/ Next run different experiments of interest that restart from the spinup experiment. # ctrl ./runylmox -r -e ismip6 -n par/yelmo_ismip6_Antarctica.nml -o output/ismip6/ctrl -p ctrl.run_step=\"transient_proj\" yelmo.restart=\"../spinup_opt11/yelmo_restart.nc\" transient_proj.scenario=\"ctrl\" tf_cor.name=\"dT_nl\" marine_shelf.gamma_quad_nl=14500 # exp05 ./runylmox -r -e ismip6 -n par/yelmo_ismip6_Antarctica.nml -o output/ismip6/exp05 -p ctrl.run_step=\"transient_proj\" yelmo.restart=\"../spinup_opt11/yelmo_restart.nc\" transient_proj.scenario=\"rcp85\" tf_cor.name=\"dT_nl\" marine_shelf.gamma_quad_nl=14500 # exp09 ./runylmox -r -e ismip6 -n par/yelmo_ismip6_Antarctica.nml -o output/ismip6/exp09 -p ctrl.run_step=\"transient_proj\" yelmo.restart=\"../spinup_opt11/yelmo_restart.nc\" transient_proj.scenario=\"rcp85\" tf_cor.name=\"dT_nl_95\" marine_shelf.gamma_quad_nl=21000 # exp10 ./runylmox -r -e ismip6 -n par/yelmo_ismip6_Antarctica.nml -o output/ismip6/exp10 -p ctrl.run_step=\"transient_proj\" yelmo.restart=\"../spinup_opt11/yelmo_restart.nc\" transient_proj.scenario=\"rcp85\" tf_cor.name=\"dT_nl_5\" marine_shelf.gamma_quad_nl=9620 # exp13 ./runylmox -r -e ismip6 -n par/yelmo_ismip6_Antarctica.nml -o output/ismip6/exp13 -p ctrl.run_step=\"transient_proj\" yelmo.restart=\"../spinup_opt11/yelmo_restart.nc\" transient_proj.scenario=\"rcp85\" tf_cor.name=\"dT_nl_pigl\" marine_shelf.gamma_quad_nl=159000 ABUMIP First make sure your distribution of yelmox and yelmo are up to date with the abumip-2021 branch. # If you need to clone: git clone https://github.com/palma-ice/yelmox.git # Clone yelmo into a sub-directory too cd yelmox git clone https://github.com/palma-ice/yelmo.git # Link to ice_data path: ln -s /media/Data/ice_data ice_data Next, checkout the right branches... cd yelmo git fetch --all git checkout abumip-2021 python3 config.py config/snowball_gfortran cd .. # In the main yelmox directory, change to the branch 'abumip-2021' and reconfigure: git fetch --all git checkout abumip-2021 python3 config.py config/snowball_gfortran cp config/runylmox.js ./ Now compile as normal, but with the yelmox_ismip6 program: make clean make yelmox_ismip6 Next use the following commands to run the three main experiments of interest. Note that abuk and abum may run much more slowly than abuc . The parameter values applied in the commands below ensure that the model parameters correspond to those used in the restart simulation, although many of them like ocean temp. anomalies in different basins or calving parameters, are no longer relevant in the ABUMIP context. It is important, however, to specify ydyn.ssa_lat_bc='marine' , as it is relevant for this experiment to apply marine boundary conditions. This is generally not used currently, as it makes the model much less stable. Note that an equilibrium spin-up simulation has already been performed, which gives good agreement with the present-day ice sheet. These results have been saved in a restart file, from which your simulations will begin (see below). # Define restart file path as a bash variable file_restart=/home/robinson/ismip6/spinup_32km_01/5/yelmo_restart.nc # Define output folder as a bash variable fldr=output/ismip6/abumip32km # Call the Yelmo commands... # ABUC - control experiment ./runylmox -r -e ismip6 -n par/yelmo_ismip6_Antarctica.nml -o ${fldr}/abuc -p abumip.scenario=\"abuc\" ctrl.run_step=\"abumip_proj\" yelmo.restart=${file_restart} transient_proj.scenario=\"ctrl\" tf_cor.name=\"dT_nl\" marine_shelf.gamma_quad_nl=14500 tf_corr_ant.ronne=0.25 tf_corr_ant.ross=0.2 tf_corr_ant.pine=-0.5 ytopo.kt=0.003 isostasy.method=0 ydyn.ssa_lat_bc='floating' # ABUK - Ocean-kill experiment ./runylmox -r -e ismip6 -n par/yelmo_ismip6_Antarctica.nml -o ${fldr}/abuk -p abumip.scenario=\"abuk\" ctrl.run_step=\"abumip_proj\" yelmo.restart=${file_restart} transient_proj.scenario=\"ctrl\" tf_cor.name=\"dT_nl\" marine_shelf.gamma_quad_nl=14500 tf_corr_ant.ronne=0.25 tf_corr_ant.ross=0.2 tf_corr_ant.pine=-0.5 ytopo.kt=0.003 isostasy.method=0 ytopo.calv_tau=1e-1 ydyn.ssa_lat_bc='marine' # ABUM - High shelf melt (400 m/yr) ./runylmox -r -e ismip6 -n par/yelmo_ismip6_Antarctica.nml -o ${fldr}/abum -p abumip.scenario=\"abum\" ctrl.run_step=\"abumip_proj\" yelmo.restart=${file_restart} transient_proj.scenario=\"ctrl\" tf_cor.name=\"dT_nl\" marine_shelf.gamma_quad_nl=14500 tf_corr_ant.ronne=0.25 tf_corr_ant.ross=0.2 tf_corr_ant.pine=-0.5 ytopo.kt=0.003 isostasy.method=0 ydyn.ssa_lat_bc='floating' That's it!","title":"YelmoX"},{"location":"running-with-yelmox/#running-with-yelmox","text":"YelmoX is a separate repository that is designed to provide supplementary libraries and programs that allow running ice-sheet simulations with realistic boundary (e.g., climate and ocean) forcing and interactions (e.g., isostatic rebound). Here you can find the basic information and steps needed to get YelmoX running.","title":"Running with YelmoX"},{"location":"running-with-yelmox/#super-quick-start","text":"A summary of commands to get started is given below. For more detailed information see subsequent sections. # Before doing anything, make sure dependencies are installed (Lis, NetCDF, runner) ########################## # Clone repository git clone https://github.com/palma-ice/yelmox.git git clone git@github.com:palma-ice/yelmox.git # or via ssh # Clone yelmo into a sub-directory too cd yelmox git clone https://github.com/palma-ice/yelmo.git git clone git@github.com:palma-ice/yelmo.git # or, via ssh # Check out your yelmox branch of interest (optional) git checkout my-branch # for an existing branch git checkout -b my-new-branch # or, to create a new one # Do the same for yelmo branch if needed, and return to yelmox directory cd yelmo git checkout my-branch cd .. # Enter yelmo directory and configure it for compiling cd yelmo python3 config.py config/snowball_gfortran # or the right config file for your system # Return to yelmox directory and configure it for compiling cd .. python3 config.py config/snowball_gfortran # or the right config file for your system # Now, compile the default program make clean make yelmox # Link to `ice_data` repository wherever you have it saved on your system ln -s path_to/ice_data # Copy the runylmox config file to the main directory cp config/runylmox.js ./ # Run a test simulation of Antarctica for 1000 yrs ./runylmox -r -e yelmox -n par/yelmo_Antarctica.nml -o output/ant-test -p ctrl.time_end=1e3","title":"Super-quick start"},{"location":"running-with-yelmox/#standard-yelmox-simulations","text":"To run YelmoX, by default we use the program yelmox.f90 . This program currently makes use of snapclim for the climatic forcing and smbpal for the snowpack and surface mass balance calculations.","title":"Standard YelmoX simulations"},{"location":"running-with-yelmox/#ismip6-simulations","text":"First make sure your distribution of yelmox and yelmo are up to date. cd yelmo git pull cd .. # In the main yelmox directory, change to the branch 'tfm2021': git pull git checkout tfm2021 # From main directory of yelmox, also reconfigure to adopt all changes: python3 config.py config/snowball_gfortran cp config/runylmox.js ./ Now compile as normal, but with the yelmox_ismip6 program: make clean make yelmox_ismip6 That's it, you are now ready to run some ISMIP6 simulations. If you need to run a spinup simulation that also optimizes basal friction, run the following command: # First run spinup simulation # (steady-state present day boundary conditions) ./runylmox -r -e ismip6 -n par/yelmo_ismip6_Antarctica.nml -o output/ismip6/spinup_opt11 -p ctrl.run_step=\"spinup_ismip6\" opt_L21.cf_min=1e-3 ytopo.kt=0.10e-2 tf_corr_ant.ronne=0.0 tf_corr_ant.ross=0.0 Or an ensemble to test different parameters too: fldr=tmp/ismip6/spinup10 jobrun ./runylmox -s -q short -w 10 -e ismip6 -n par/yelmo_ismip6_Antarctica.nml -- -o ${fldr} -p ctrl.run_step=\"spinup_ismip6\" opt_L21.cf_min=1e-3 ytopo.kt=0.10e-2,0.20e-2,0.30e-2,0.40e-2 tf_corr_ant.ronne=0.0,0.25 tf_corr_ant.ross=0.0,0.2 If you already have a spinup simulation available, you can skip that step. You can also copy one from here: mkdir output/ismip6 cp -r /home/robinson/yelmox/output/ismip6/spinup_opt11 output/ismip6/ Next run different experiments of interest that restart from the spinup experiment. # ctrl ./runylmox -r -e ismip6 -n par/yelmo_ismip6_Antarctica.nml -o output/ismip6/ctrl -p ctrl.run_step=\"transient_proj\" yelmo.restart=\"../spinup_opt11/yelmo_restart.nc\" transient_proj.scenario=\"ctrl\" tf_cor.name=\"dT_nl\" marine_shelf.gamma_quad_nl=14500 # exp05 ./runylmox -r -e ismip6 -n par/yelmo_ismip6_Antarctica.nml -o output/ismip6/exp05 -p ctrl.run_step=\"transient_proj\" yelmo.restart=\"../spinup_opt11/yelmo_restart.nc\" transient_proj.scenario=\"rcp85\" tf_cor.name=\"dT_nl\" marine_shelf.gamma_quad_nl=14500 # exp09 ./runylmox -r -e ismip6 -n par/yelmo_ismip6_Antarctica.nml -o output/ismip6/exp09 -p ctrl.run_step=\"transient_proj\" yelmo.restart=\"../spinup_opt11/yelmo_restart.nc\" transient_proj.scenario=\"rcp85\" tf_cor.name=\"dT_nl_95\" marine_shelf.gamma_quad_nl=21000 # exp10 ./runylmox -r -e ismip6 -n par/yelmo_ismip6_Antarctica.nml -o output/ismip6/exp10 -p ctrl.run_step=\"transient_proj\" yelmo.restart=\"../spinup_opt11/yelmo_restart.nc\" transient_proj.scenario=\"rcp85\" tf_cor.name=\"dT_nl_5\" marine_shelf.gamma_quad_nl=9620 # exp13 ./runylmox -r -e ismip6 -n par/yelmo_ismip6_Antarctica.nml -o output/ismip6/exp13 -p ctrl.run_step=\"transient_proj\" yelmo.restart=\"../spinup_opt11/yelmo_restart.nc\" transient_proj.scenario=\"rcp85\" tf_cor.name=\"dT_nl_pigl\" marine_shelf.gamma_quad_nl=159000","title":"ISMIP6 simulations"},{"location":"running-with-yelmox/#abumip","text":"First make sure your distribution of yelmox and yelmo are up to date with the abumip-2021 branch. # If you need to clone: git clone https://github.com/palma-ice/yelmox.git # Clone yelmo into a sub-directory too cd yelmox git clone https://github.com/palma-ice/yelmo.git # Link to ice_data path: ln -s /media/Data/ice_data ice_data Next, checkout the right branches... cd yelmo git fetch --all git checkout abumip-2021 python3 config.py config/snowball_gfortran cd .. # In the main yelmox directory, change to the branch 'abumip-2021' and reconfigure: git fetch --all git checkout abumip-2021 python3 config.py config/snowball_gfortran cp config/runylmox.js ./ Now compile as normal, but with the yelmox_ismip6 program: make clean make yelmox_ismip6 Next use the following commands to run the three main experiments of interest. Note that abuk and abum may run much more slowly than abuc . The parameter values applied in the commands below ensure that the model parameters correspond to those used in the restart simulation, although many of them like ocean temp. anomalies in different basins or calving parameters, are no longer relevant in the ABUMIP context. It is important, however, to specify ydyn.ssa_lat_bc='marine' , as it is relevant for this experiment to apply marine boundary conditions. This is generally not used currently, as it makes the model much less stable. Note that an equilibrium spin-up simulation has already been performed, which gives good agreement with the present-day ice sheet. These results have been saved in a restart file, from which your simulations will begin (see below). # Define restart file path as a bash variable file_restart=/home/robinson/ismip6/spinup_32km_01/5/yelmo_restart.nc # Define output folder as a bash variable fldr=output/ismip6/abumip32km # Call the Yelmo commands... # ABUC - control experiment ./runylmox -r -e ismip6 -n par/yelmo_ismip6_Antarctica.nml -o ${fldr}/abuc -p abumip.scenario=\"abuc\" ctrl.run_step=\"abumip_proj\" yelmo.restart=${file_restart} transient_proj.scenario=\"ctrl\" tf_cor.name=\"dT_nl\" marine_shelf.gamma_quad_nl=14500 tf_corr_ant.ronne=0.25 tf_corr_ant.ross=0.2 tf_corr_ant.pine=-0.5 ytopo.kt=0.003 isostasy.method=0 ydyn.ssa_lat_bc='floating' # ABUK - Ocean-kill experiment ./runylmox -r -e ismip6 -n par/yelmo_ismip6_Antarctica.nml -o ${fldr}/abuk -p abumip.scenario=\"abuk\" ctrl.run_step=\"abumip_proj\" yelmo.restart=${file_restart} transient_proj.scenario=\"ctrl\" tf_cor.name=\"dT_nl\" marine_shelf.gamma_quad_nl=14500 tf_corr_ant.ronne=0.25 tf_corr_ant.ross=0.2 tf_corr_ant.pine=-0.5 ytopo.kt=0.003 isostasy.method=0 ytopo.calv_tau=1e-1 ydyn.ssa_lat_bc='marine' # ABUM - High shelf melt (400 m/yr) ./runylmox -r -e ismip6 -n par/yelmo_ismip6_Antarctica.nml -o ${fldr}/abum -p abumip.scenario=\"abum\" ctrl.run_step=\"abumip_proj\" yelmo.restart=${file_restart} transient_proj.scenario=\"ctrl\" tf_cor.name=\"dT_nl\" marine_shelf.gamma_quad_nl=14500 tf_corr_ant.ronne=0.25 tf_corr_ant.ross=0.2 tf_corr_ant.pine=-0.5 ytopo.kt=0.003 isostasy.method=0 ydyn.ssa_lat_bc='floating' That's it!","title":"ABUMIP"},{"location":"snapclim/","text":"Snapshot climate (snapclim) The snapclim module is designed to determine climatic forcing, i.e., monthly temperature and precipitation, for a given point in time. This can be acheived by applying a temperature anomaly, or by interpolating snapshots of climate states available for different times. The \"hybrid\" method. This is my preferred method and is set up to be rather flexible, and I think is a good place to start for these simulations. It is comprised of an annual mean temperature anomaly time series from 300 kyr ago to today obtained from several spliced paleo reconstructions plus a monthly seasonal cycle over the 300 kyr obtained from a climber2 paleo run. So with the monthly values and the annual mean, you can get monthly temp anomalies over 300 kyr. There are more details in the attached manuscript that was never yet submitted... To activate this method, in the parameter file, set the following parameters in the group \"snapclim\": atm_type = \"hybrid\" ocn_type = \"hybrid\" Then in the group \"snapclim_hybrid\", you can specify: f_eem = 0.4 # Controls the maximum temp anomaly during the Eemian f_glac = 1.0 # Controls the minimum temp anomaly during the glacial period f_hol = 0.5 # Controls the maximum temp anomaly during the Holocene f_seas = 1.0 # Controls the magnitude of the seasonal cycle f_to = 0.2 # Defines the oceanic temperature anomaly relative # to the annual mean atmospheric temp anomaly","title":"Snapshot climate (snapclim)"},{"location":"snapclim/#snapshot-climate-snapclim","text":"The snapclim module is designed to determine climatic forcing, i.e., monthly temperature and precipitation, for a given point in time. This can be acheived by applying a temperature anomaly, or by interpolating snapshots of climate states available for different times.","title":"Snapshot climate (snapclim)"},{"location":"snapclim/#the-hybrid-method","text":"This is my preferred method and is set up to be rather flexible, and I think is a good place to start for these simulations. It is comprised of an annual mean temperature anomaly time series from 300 kyr ago to today obtained from several spliced paleo reconstructions plus a monthly seasonal cycle over the 300 kyr obtained from a climber2 paleo run. So with the monthly values and the annual mean, you can get monthly temp anomalies over 300 kyr. There are more details in the attached manuscript that was never yet submitted... To activate this method, in the parameter file, set the following parameters in the group \"snapclim\": atm_type = \"hybrid\" ocn_type = \"hybrid\" Then in the group \"snapclim_hybrid\", you can specify: f_eem = 0.4 # Controls the maximum temp anomaly during the Eemian f_glac = 1.0 # Controls the minimum temp anomaly during the glacial period f_hol = 0.5 # Controls the maximum temp anomaly during the Holocene f_seas = 1.0 # Controls the magnitude of the seasonal cycle f_to = 0.2 # Defines the oceanic temperature anomaly relative # to the annual mean atmospheric temp anomaly","title":"The \"hybrid\" method."}]}