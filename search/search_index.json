{"config":{"lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Yelmo Welcome to Yelmo , an easy to use continental ice sheet model. Yelmo is a 3D ice-sheet-shelf model solving for the coupled dynamics and thermodynamics of the ice sheet system. Yelmo can be used for idealized simulations, stand-alone ice sheet simulations and fully coupled ice-sheet and climate simulations. Yelmo has been designed to operate as a stand-alone model or to be easily plugged in as a module in another program. The key to its flexibility is that no variables are defined globally and parameters are defined according to the domain being modeled. In this way, all variables and calculations are store in an object that entirely represents the model domain. The physics and design of Yelmo are described in the following article: Robinson, A., Alvarez-Solas, J., Montoya, M., Goelzer, H., Greve, R., and Ritz, C.: Description and validation of the ice-sheet model Yelmo (version 1.0), Geosci. Model Dev., 13, 2805\u20132823, https://doi.org/10.5194/gmd-13-2805-2020 , 2020. The Yelmo code repository can be found here: https://github.com/palma-ice/yelmo General model structure - classes and usage yelmo_class The Yelmo class defines all data related to a model domain, such as Greenland or Antarctica. As seen below in the yelmo_class defintion, the 'class' is simply a user-defined Fortran type that contains additional types representing various parameters, variables or sets of module variables. type yelmo_class type(yelmo_param_class) :: par ! General domain parameters type(ygrid_class) :: grd ! Grid definition type(ytopo_class) :: tpo ! Topography variables type(ydyn_class) :: dyn ! Dynamics variables type(ymat_class) :: mat ! Material variables type(ytherm_class) :: thrm ! Thermodynamics variables type(ybound_class) :: bnd ! Boundary variables to drive model type(ydata_class) :: dta ! Data variables for comparison type(yregions_class) :: reg ! Regionally aggregated variables end type Likewise the module variables are defined in a similar way, e.g. ytopo_class that defines variables and parameters associated with the topography: type ytopo_class type(ytopo_param_class) :: par ! Parameters type(ytopo_state_class) :: now ! Variables end type Submodules such as ytopo_class include parameter definitions relevant to topography calculations, as well as all variables that define the state of the domain being modeled. Example model domain intialization The below code snippet shows an example of how to initialize an instance of Yelmo inside of a program, run the model forward in time and then terminate the instance. ! === Initialize ice sheet model ===== ! General initialization of yelmo constants (used globally, only once per program) call yelmo_global_init(path_const) ! Initialize Yelmo objects (multiple yelmo objects can be initialized if needed) ! In this case `yelmo1` is the Yelmo object to initialize and `path_par` is the ! path to the parameter file to load for the configuration information. This ! command will also initialize the domain grid and load initial topographic ! variables. call yelmo_init(yelmo1,filename=path_par,grid_def=\"file\",time=time_init) ! === Load initial boundary conditions for current time and yelmo state ===== ! These variables can be loaded from a file, or passed from another ! component being simulated. Yelmo does not care about the source, ! it only needs all variables in the `bnd` class to be populated. ! ybound: z_bed, z_sl, H_sed, H_w, smb, T_srf, bmb_shlf, T_shlf, Q_geo yelmo1%bnd%z_bed = [2D array] yelmo1%bnd%z_sl = [2D array] yelmo1%bnd%H_sed = [2D array] yelmo1%bnd%H_w = [2D array] yelmo1%bnd%smb = [2D array] yelmo1%bnd%T_srf = [2D array] yelmo1%bnd%bmb_shlf = [2D array] yelmo1%bnd%T_shlf = [2D array] yelmo1%bnd%Q_geo = [2D array] ! Print summary of initial boundary conditions call yelmo_print_bound(yelmo1%bnd) ! Next, initialize the state variables (dyn,therm,mat) ! (in this case, initialize temps with robin method) call yelmo_init_state(yelmo1,time=time_init,thrm_method=\"robin\") ! Run yelmo for eg 100.0 years with constant boundary conditions and topo ! to equilibrate thermodynamics and dynamics ! (impose a constant, small dt=1yr to reduce possibility for instabilities) call yelmo_update_equil(yelmo1,time,time_tot=100.0,topo_fixed=.FALSE.,dt=1.0) ! == YELMO INITIALIZATION COMPLETE == ! Note: the above routines `yelmo_init_state` and `yelmo_update_equil` ! are optional, if the user prefers another way to initialize the state variables. ! == Start time looping and run the model == ! Advance timesteps do n = 1, ntot ! Get current time time = time_init + n*dt ! Update the Yelmo ice sheet call yelmo_update(yelmo1,time) ! Here you may be updating `yelmo1%bnd` variables to drive the model transiently. end do ! == Finalize Yelmo instance == call yelmo_end(yelmo1,time=time) That's it! See Getting started to see how to get the code, compile a test program and run simulations.","title":"Home"},{"location":"#yelmo","text":"Welcome to Yelmo , an easy to use continental ice sheet model. Yelmo is a 3D ice-sheet-shelf model solving for the coupled dynamics and thermodynamics of the ice sheet system. Yelmo can be used for idealized simulations, stand-alone ice sheet simulations and fully coupled ice-sheet and climate simulations. Yelmo has been designed to operate as a stand-alone model or to be easily plugged in as a module in another program. The key to its flexibility is that no variables are defined globally and parameters are defined according to the domain being modeled. In this way, all variables and calculations are store in an object that entirely represents the model domain. The physics and design of Yelmo are described in the following article: Robinson, A., Alvarez-Solas, J., Montoya, M., Goelzer, H., Greve, R., and Ritz, C.: Description and validation of the ice-sheet model Yelmo (version 1.0), Geosci. Model Dev., 13, 2805\u20132823, https://doi.org/10.5194/gmd-13-2805-2020 , 2020. The Yelmo code repository can be found here: https://github.com/palma-ice/yelmo","title":"Yelmo"},{"location":"#general-model-structure-classes-and-usage","text":"","title":"General model structure - classes and usage"},{"location":"#yelmo_class","text":"The Yelmo class defines all data related to a model domain, such as Greenland or Antarctica. As seen below in the yelmo_class defintion, the 'class' is simply a user-defined Fortran type that contains additional types representing various parameters, variables or sets of module variables. type yelmo_class type(yelmo_param_class) :: par ! General domain parameters type(ygrid_class) :: grd ! Grid definition type(ytopo_class) :: tpo ! Topography variables type(ydyn_class) :: dyn ! Dynamics variables type(ymat_class) :: mat ! Material variables type(ytherm_class) :: thrm ! Thermodynamics variables type(ybound_class) :: bnd ! Boundary variables to drive model type(ydata_class) :: dta ! Data variables for comparison type(yregions_class) :: reg ! Regionally aggregated variables end type Likewise the module variables are defined in a similar way, e.g. ytopo_class that defines variables and parameters associated with the topography: type ytopo_class type(ytopo_param_class) :: par ! Parameters type(ytopo_state_class) :: now ! Variables end type Submodules such as ytopo_class include parameter definitions relevant to topography calculations, as well as all variables that define the state of the domain being modeled.","title":"yelmo_class"},{"location":"#example-model-domain-intialization","text":"The below code snippet shows an example of how to initialize an instance of Yelmo inside of a program, run the model forward in time and then terminate the instance. ! === Initialize ice sheet model ===== ! General initialization of yelmo constants (used globally, only once per program) call yelmo_global_init(path_const) ! Initialize Yelmo objects (multiple yelmo objects can be initialized if needed) ! In this case `yelmo1` is the Yelmo object to initialize and `path_par` is the ! path to the parameter file to load for the configuration information. This ! command will also initialize the domain grid and load initial topographic ! variables. call yelmo_init(yelmo1,filename=path_par,grid_def=\"file\",time=time_init) ! === Load initial boundary conditions for current time and yelmo state ===== ! These variables can be loaded from a file, or passed from another ! component being simulated. Yelmo does not care about the source, ! it only needs all variables in the `bnd` class to be populated. ! ybound: z_bed, z_sl, H_sed, H_w, smb, T_srf, bmb_shlf, T_shlf, Q_geo yelmo1%bnd%z_bed = [2D array] yelmo1%bnd%z_sl = [2D array] yelmo1%bnd%H_sed = [2D array] yelmo1%bnd%H_w = [2D array] yelmo1%bnd%smb = [2D array] yelmo1%bnd%T_srf = [2D array] yelmo1%bnd%bmb_shlf = [2D array] yelmo1%bnd%T_shlf = [2D array] yelmo1%bnd%Q_geo = [2D array] ! Print summary of initial boundary conditions call yelmo_print_bound(yelmo1%bnd) ! Next, initialize the state variables (dyn,therm,mat) ! (in this case, initialize temps with robin method) call yelmo_init_state(yelmo1,time=time_init,thrm_method=\"robin\") ! Run yelmo for eg 100.0 years with constant boundary conditions and topo ! to equilibrate thermodynamics and dynamics ! (impose a constant, small dt=1yr to reduce possibility for instabilities) call yelmo_update_equil(yelmo1,time,time_tot=100.0,topo_fixed=.FALSE.,dt=1.0) ! == YELMO INITIALIZATION COMPLETE == ! Note: the above routines `yelmo_init_state` and `yelmo_update_equil` ! are optional, if the user prefers another way to initialize the state variables. ! == Start time looping and run the model == ! Advance timesteps do n = 1, ntot ! Get current time time = time_init + n*dt ! Update the Yelmo ice sheet call yelmo_update(yelmo1,time) ! Here you may be updating `yelmo1%bnd` variables to drive the model transiently. end do ! == Finalize Yelmo instance == call yelmo_end(yelmo1,time=time) That's it! See Getting started to see how to get the code, compile a test program and run simulations.","title":"Example model domain intialization"},{"location":"dependencies/","text":"Dependencies Yelmo is dependent on the following libraries: NetCDF Library of Iterative Solvers for Linear Systems [Optional] 'runner' Python library (alex-robinson fork) Installation tips for each dependency can be found below. Installing NetCDF (preferably version 4.0 or higher) The NetCDF library is typically available with different distributions (Linux, Mac, etc). Along with installing libnetcdf , it will be necessary to install the package libnetcdf-dev . Installing the NetCDF viewing program ncview is also recommended. If you want to install NetCDF from source, then you must install both the netcdf-c and subsequently netcdf-fortran libraries. The source code and installation instructions are available from the Unidata website: https://www.unidata.ucar.edu/software/netcdf/docs/getting_and_building_netcdf.html Installing LIS Download the LIS source: https://www.ssisc.org/lis/ Configure the package (where is the desired installation location), and install it in the location of your choice (below defined as $LISROOT ). Also, make sure to enable the Fortran90 interface: cd lis-2.0.18 ./configure --prefix=$LISROOT --enable-f90 make make install make install check Note: make sure to set the environment variables CC and FC , in order to set a specific compiler, for example for gcc/gfortran use the following configure command: CC=gcc FC=gfortran ./configure --prefix=$LISROOT --enable-f90 Add LIS path to the LD_LIBRARY_PATH in .bash_profile , .bashrc or .bash_aliases : # lis library paths LD_LIBRARY_PATH=$LISROOT/lib:$LD_LIBRARY_PATH export LD_LIBRARY_PATH That's it. LIS should now be available to use with Yelmo. Installing runner Clone / download the runner repository from https://github.com/alex-robinson/runner . Save it an any location you want. Install runner to your system's Python installation via pip . git clone https://github.com/alex-robinson/runner.git cd runner pip install ./ That's it! Now check that system command job is available by running job -h . Note that install method python setup.py install should be avoided if possible to maintain Python system integrity.","title":"Dependencies"},{"location":"dependencies/#dependencies","text":"Yelmo is dependent on the following libraries: NetCDF Library of Iterative Solvers for Linear Systems [Optional] 'runner' Python library (alex-robinson fork) Installation tips for each dependency can be found below.","title":"Dependencies"},{"location":"dependencies/#installing-netcdf-preferably-version-40-or-higher","text":"The NetCDF library is typically available with different distributions (Linux, Mac, etc). Along with installing libnetcdf , it will be necessary to install the package libnetcdf-dev . Installing the NetCDF viewing program ncview is also recommended. If you want to install NetCDF from source, then you must install both the netcdf-c and subsequently netcdf-fortran libraries. The source code and installation instructions are available from the Unidata website: https://www.unidata.ucar.edu/software/netcdf/docs/getting_and_building_netcdf.html","title":"Installing NetCDF (preferably version 4.0 or higher)"},{"location":"dependencies/#installing-lis","text":"Download the LIS source: https://www.ssisc.org/lis/ Configure the package (where is the desired installation location), and install it in the location of your choice (below defined as $LISROOT ). Also, make sure to enable the Fortran90 interface: cd lis-2.0.18 ./configure --prefix=$LISROOT --enable-f90 make make install make install check Note: make sure to set the environment variables CC and FC , in order to set a specific compiler, for example for gcc/gfortran use the following configure command: CC=gcc FC=gfortran ./configure --prefix=$LISROOT --enable-f90 Add LIS path to the LD_LIBRARY_PATH in .bash_profile , .bashrc or .bash_aliases : # lis library paths LD_LIBRARY_PATH=$LISROOT/lib:$LD_LIBRARY_PATH export LD_LIBRARY_PATH That's it. LIS should now be available to use with Yelmo.","title":"Installing LIS"},{"location":"dependencies/#installing-runner","text":"Clone / download the runner repository from https://github.com/alex-robinson/runner . Save it an any location you want. Install runner to your system's Python installation via pip . git clone https://github.com/alex-robinson/runner.git cd runner pip install ./ That's it! Now check that system command job is available by running job -h . Note that install method python setup.py install should be avoided if possible to maintain Python system integrity.","title":"Installing runner"},{"location":"example-programs/","text":"Example programs The Yelmo base code provides a static library interface that can be used in other programs, as well as a couple of stand-alone programs for running certain benchmarks. Here we provide more examples of how to use Yelmo: Program template to connect with other models/components. Stand-alone ice sheet with full boundary forcing. In both cases, it is necessary to download the Yelmo repository separately, as well as compile the Yelmo static library (see Getting started ). Program template This is a minimalistic setup that allows you to run Yelmo with no dependencies and a straightforward Makefile. This template can be used to design a new stand-alone Yelmo experiment, or to provide guidance when adding Yelmo to another program. Clone the repository from https://github.com/palma-ice/yelmot Stand-alone ice sheet with full boundary forcing (yelmox) This setup is suitable for glacial-cycle simulations, future simulations or any other typical (realistic) ice-sheet model simulation. Clone the repository from https://github.com/palma-ice/yelmox","title":"Examples"},{"location":"example-programs/#example-programs","text":"The Yelmo base code provides a static library interface that can be used in other programs, as well as a couple of stand-alone programs for running certain benchmarks. Here we provide more examples of how to use Yelmo: Program template to connect with other models/components. Stand-alone ice sheet with full boundary forcing. In both cases, it is necessary to download the Yelmo repository separately, as well as compile the Yelmo static library (see Getting started ).","title":"Example programs"},{"location":"example-programs/#program-template","text":"This is a minimalistic setup that allows you to run Yelmo with no dependencies and a straightforward Makefile. This template can be used to design a new stand-alone Yelmo experiment, or to provide guidance when adding Yelmo to another program. Clone the repository from https://github.com/palma-ice/yelmot","title":"Program template"},{"location":"example-programs/#stand-alone-ice-sheet-with-full-boundary-forcing-yelmox","text":"This setup is suitable for glacial-cycle simulations, future simulations or any other typical (realistic) ice-sheet model simulation. Clone the repository from https://github.com/palma-ice/yelmox","title":"Stand-alone ice sheet with full boundary forcing (yelmox)"},{"location":"getting-started/","text":"Getting started Here you can find the basic information and steps needed to get Yelmo running. Super-quick start A summary of commands to get started is given below. For more detailed information see subsequent sections. # Clone repository git clone https://github.com/palma-ice/yelmo.git git clone git@github.com:palma-ice/yelmo.git # via ssh # Enter directory and run configuration script cd yelmo python config.py config/pik_ifort # Compile the benchmarks program make clean make benchmarks # Run a test simulation of the EISMINT1-moving experiment ./runylmo -r -e benchmarks -o output/eismint1-moving -n par-gmd/yelmo_EISMINT_moving.nml # Compile the initmip program and run a simulation of Antarctica make initmip ./runylmo -r -e initmip -o output/ant-pd -n par/yelmo_initmip.nml -p ctrl.clim_nm=\"clim_pd\" Dependencies See: Dependencies for installation tips. NetCDF library (preferably version 4.0 or higher) LIS: Library of Iterative Solvers for Linear Systems [Optional] Python 3.x, which is only needed for automatic configuration of the Makefile and the use of the script runylmo for job preparation and submission. [Optional] 'runner' Python library: https://github.com/alex-robinson/runner . Used for changing parameters at the command line using runylmo , and for running ensembles. Directory structure config/ Configuration files for compilation on different systems. input/ Location of any input data needed by the model. libs/ Auxiliary libraries nesecessary for running the model. libyelmo/ Folder containing all compiled files in a standard way with lib/, include/ and bin/ folders. output/ Default location for model output. par/ Default parameter files that manage the model configuration. src/ Source code for Yelmo. tests/ Source code and analysis scripts for specific model benchmarks and tests. Usage Follow the steps below to (1) obtain the code, (2) configure the Makefile for your system, (3) compile the Yelmo static library and an executable program and (4) run a test simulation. 1. Get the code. Clone the repository from https://github.com/palma-ice/yelmo : # Clone repository git clone https://github.com/palma-ice/yelmo.git $YELMOROOT git clone git@github.com:palma-ice/yelmo.git $YELMOROOT # via ssh cd $YELMOROOT where $YELMOROOT is the installation directory. If you plan to make changes to the code, it is wise to check out a new branch: git checkout -b user-dev You should now be working on the branch user-dev . 2. Create the system-specific Makefile. To compile Yelmo, you need to generate a Makefile that is appropriate for your system. In the folder config , you need to specify a configuration file that defines the compiler and flags, including definition of the paths to the NetCDF and LIS libraries. You can use another file in the config folder as a template, e.g., cd config cp pik_ifort myhost_mycompiler then modify the file myhost_mycompiler to match your paths. Back in $YELMOROOT , you can then generate your Makefile with the provided python configuration script: cd $YELMOROOT python config.py config/myhost_mycompiler The result should be a Makefile in $YELMOROOT that is ready for use. Alternative configuration - quickstart with Docker and VS Code Instead of a manual install, one way to get up and running quickly with Yelmo is with VS Code and Docker. It works on any plattform and uses a Linux based container. You don't need to know Docker or VS Code to get started. Just install the following: Docker VS Code install the remote development extension Then make sure that Docker is running and start VS Code. Open the folder with the Yelmo code. Say Yes, when VS Code asks you if you want to open it in the container. Now you can directly go to step 3 below, just make sure that you use the terminal in VS Code. 3. Compile the code. Now you are ready to compile Yelmo as a static library: make clean # This step is very important to avoid errors!! make yelmo-static [debug=1] This will compile all of the Yelmo modules and libraries (as defined in config/Makefile_yelmo.mk ), and link them in a static library. All compiled files can be found in the folder libyelmo/ . Once the static library has been compiled, it can be used inside of external Fortran programs and modules via the statement use yelmo . To include/link yelmo-static during compilation of another program, its location must be defined: INC_YELMO = -I${YELMOROOT}/include LIB_YELMO = -L${YELMOROOT}/include -lyelmo Alternatively, several test programs exist in the folder tests/ to run Yelmo as a stand-alone ice sheet. For example, it's possible to run different EISMINT benchmarks, MISMIP benchmarks and the ISIMIP6 INITMIP simulation for Greenland, respectively: make benchmarks # compiles the program `libyelmo/bin/yelmo_benchmarks.x` make mismip # compiles the program `libyelmo/bin/yelmo_mismip.x` make initmip # compiles the program `libyelmo/bin/yelmo_initmip.x` The Makefile additionally allows you to specify debugging compiler flags with the option debug=1 , in case you need to debug the code (e.g., make benchmarks debug=1 ). Using this option, the code will run much slower, so this option is not recommended unless necessary. 4. Run the model. Once an executable has been created, you can run the model. This can be achieved via the included Python job submission script runylmo . The following steps are carried out via the script: The output directory is created. The executable is copied to the output directory The relevant parameter files are copied to the output directory. Links to the input data paths ( input and ice_data ) are created in the output directory. Note that many simulations, such as benchmark experiments, do not depend on these external data sources, but the links are made anyway. The executable is run from the output directory, either as a background process or it is submitted to the queue via sbatch (the SLURM workload manager). To run a benchmark simulation, for example, use the following command: ./runylmo -r -e benchmarks -o output/test -n par/yelmo_EISMINT.nml where the option -r implies that the model should be run as a background process. If this is omitted, then the output directory will be populated, but no executable will be run, while -s instead will submit the simulation to cluster queue system instead of running in the background. The option -e lets you specify the executable. For some standard cases, shortcuts have been created: benchmarks = libyelmo/bin/yelmo_benchmarks.x mismip = libyelmo/bin/yemo_mismip.x initmip = libyelmo/bin/yelmo_initmip.x The last two mandatory arguments -o OUTDIR and -n PAR_PATH are the output/run directory and the parameter file to be used for this simulation, respectively. In the case of the above simulation, the output directory is defined as output/test , where all model parameters (loaded from the file par/yelmo_EISMINT.nml ) and model output can be found. It is also possible to modify parameters inline via the option -p KEY=VAL [KEY=VAL ...] . The parameter should be specified with its namelist group and its name. E.g., to change the resolution of the EISMINT benchmark experiment to 10km, use: ./runylmo -r -e benchmarks -o output/test -n par/yelmo_EISMINT.nml -p ctrl.dx=10 See runylmo -h for more details on the run script. Test cases The published model description includes several test simulations for validation of the model's performance. The following section describes how to perform these tests using the same model version documented in the article. From this point, it is assumed that the user has already configured the model for their system (see https://palma-ice.github.io/yelmo-docs) and is ready to compile the mode. 1. EISMINT1 moving margin experiment To perform the moving margin experiment, compile the benchmarks executable and call it with the EISMINT parameter file: make benchmarks ./runylmo -r -e benchmarks -o output/eismint-moving -n par-gmd/yelmo_EISMINT_moving.nml 2. EISMINT2 EXPA To perform Experiment A from the EISMINT2 benchmarks, compile the benchmarks executable and call it with the EXPA parameter file: make benchmarks ./runylmo -r -e benchmarks -o output/eismint-expa -n par-gmd/yelmo_EISMINT_expa.nml 3. EISMINT2 EXPF To perform Experiment F from the EISMINT2 benchmarks, compile the benchmarks executable and call it with the EXPF parameter file: make benchmarks ./runylmo -r -e benchmarks -o output/eismint-expf -n par-gmd/yelmo_EISMINT_expf.nml 4. MISMIP RF To perform the MISMIP rate factor experiment, compile the mismip executable and call it with the MISMIP parameter file the three parameter permutations of interest (default, subgrid and subgrid+gl-scaling): make mismip ./runylmo -r -e mismip -o output/mismip-rf-0 -n par-gmd/yelmo_MISMIP3D.nml -p ydyn.beta_gl_stag=0 ydyn.beta_gl_scale=0 ./runylmo -r -e mismip -o output/mismip-rf-1 -n par-gmd/yelmo_MISMIP3D.nml -p ydyn.beta_gl_stag=3 ydyn.beta_gl_scale=0 ./runylmo -r -e mismip -o output/mismip-rf-2 -n par-gmd/yelmo_MISMIP3D.nml -p ydyn.beta_gl_stag=3 ydyn.beta_gl_scale=2 To additionally change the resolution of the simulations change the parameter mismip.dx , e.g. for the default simulation with 10km resolution , call: ./runylmo -r -e mismip -o output/mismip-rf-0-10km -n par-gmd/yelmo_MISMIP3D.nml -p ydyn.beta_gl_stag=0 ydyn.beta_gl_scale=0 mismip.dx=10 5. Age profile experiments To perform the age profile experiments, compile the Fortran program tests/test_icetemp.f90 and run it: make icetemp ./libyelmo/bin/test_icetemp.x To perform the different permutations, it is necessary to recompile for single or double precision after changing the precision parameter prec in the file src/yelmo_defs.f90 . The number of vertical grid points can be specified in the main program file, as well as the output filename. 6. Antarctica present-day and glacial simulations To perform the Antarctica simulations as presented in the paper, it is necessary to compile the initmip executable and run with the present-day (pd) and glacial (lgm) parameter values: make initmip ./runylmo -r -e initmip -o output/ant-pd -n par-gmd/yelmo_Antarctica.nml -p ctrl.clim_nm=\"clim_pd\" ./runylmo -r -e initmip -o output/ant-lgm -n par-gmd/yelmo_Antarctica.nml -p ctrl.clim_nm=\"clim_lgm\"","title":"Getting started"},{"location":"getting-started/#getting-started","text":"Here you can find the basic information and steps needed to get Yelmo running.","title":"Getting started"},{"location":"getting-started/#super-quick-start","text":"A summary of commands to get started is given below. For more detailed information see subsequent sections. # Clone repository git clone https://github.com/palma-ice/yelmo.git git clone git@github.com:palma-ice/yelmo.git # via ssh # Enter directory and run configuration script cd yelmo python config.py config/pik_ifort # Compile the benchmarks program make clean make benchmarks # Run a test simulation of the EISMINT1-moving experiment ./runylmo -r -e benchmarks -o output/eismint1-moving -n par-gmd/yelmo_EISMINT_moving.nml # Compile the initmip program and run a simulation of Antarctica make initmip ./runylmo -r -e initmip -o output/ant-pd -n par/yelmo_initmip.nml -p ctrl.clim_nm=\"clim_pd\"","title":"Super-quick start"},{"location":"getting-started/#dependencies","text":"See: Dependencies for installation tips. NetCDF library (preferably version 4.0 or higher) LIS: Library of Iterative Solvers for Linear Systems [Optional] Python 3.x, which is only needed for automatic configuration of the Makefile and the use of the script runylmo for job preparation and submission. [Optional] 'runner' Python library: https://github.com/alex-robinson/runner . Used for changing parameters at the command line using runylmo , and for running ensembles.","title":"Dependencies"},{"location":"getting-started/#directory-structure","text":"config/ Configuration files for compilation on different systems. input/ Location of any input data needed by the model. libs/ Auxiliary libraries nesecessary for running the model. libyelmo/ Folder containing all compiled files in a standard way with lib/, include/ and bin/ folders. output/ Default location for model output. par/ Default parameter files that manage the model configuration. src/ Source code for Yelmo. tests/ Source code and analysis scripts for specific model benchmarks and tests.","title":"Directory structure"},{"location":"getting-started/#usage","text":"Follow the steps below to (1) obtain the code, (2) configure the Makefile for your system, (3) compile the Yelmo static library and an executable program and (4) run a test simulation.","title":"Usage"},{"location":"getting-started/#1-get-the-code","text":"Clone the repository from https://github.com/palma-ice/yelmo : # Clone repository git clone https://github.com/palma-ice/yelmo.git $YELMOROOT git clone git@github.com:palma-ice/yelmo.git $YELMOROOT # via ssh cd $YELMOROOT where $YELMOROOT is the installation directory. If you plan to make changes to the code, it is wise to check out a new branch: git checkout -b user-dev You should now be working on the branch user-dev .","title":"1. Get the code."},{"location":"getting-started/#2-create-the-system-specific-makefile","text":"To compile Yelmo, you need to generate a Makefile that is appropriate for your system. In the folder config , you need to specify a configuration file that defines the compiler and flags, including definition of the paths to the NetCDF and LIS libraries. You can use another file in the config folder as a template, e.g., cd config cp pik_ifort myhost_mycompiler then modify the file myhost_mycompiler to match your paths. Back in $YELMOROOT , you can then generate your Makefile with the provided python configuration script: cd $YELMOROOT python config.py config/myhost_mycompiler The result should be a Makefile in $YELMOROOT that is ready for use.","title":"2. Create the system-specific Makefile."},{"location":"getting-started/#alternative-configuration-quickstart-with-docker-and-vs-code","text":"Instead of a manual install, one way to get up and running quickly with Yelmo is with VS Code and Docker. It works on any plattform and uses a Linux based container. You don't need to know Docker or VS Code to get started. Just install the following: Docker VS Code install the remote development extension Then make sure that Docker is running and start VS Code. Open the folder with the Yelmo code. Say Yes, when VS Code asks you if you want to open it in the container. Now you can directly go to step 3 below, just make sure that you use the terminal in VS Code.","title":"Alternative configuration - quickstart with Docker and VS Code"},{"location":"getting-started/#3-compile-the-code","text":"Now you are ready to compile Yelmo as a static library: make clean # This step is very important to avoid errors!! make yelmo-static [debug=1] This will compile all of the Yelmo modules and libraries (as defined in config/Makefile_yelmo.mk ), and link them in a static library. All compiled files can be found in the folder libyelmo/ . Once the static library has been compiled, it can be used inside of external Fortran programs and modules via the statement use yelmo . To include/link yelmo-static during compilation of another program, its location must be defined: INC_YELMO = -I${YELMOROOT}/include LIB_YELMO = -L${YELMOROOT}/include -lyelmo Alternatively, several test programs exist in the folder tests/ to run Yelmo as a stand-alone ice sheet. For example, it's possible to run different EISMINT benchmarks, MISMIP benchmarks and the ISIMIP6 INITMIP simulation for Greenland, respectively: make benchmarks # compiles the program `libyelmo/bin/yelmo_benchmarks.x` make mismip # compiles the program `libyelmo/bin/yelmo_mismip.x` make initmip # compiles the program `libyelmo/bin/yelmo_initmip.x` The Makefile additionally allows you to specify debugging compiler flags with the option debug=1 , in case you need to debug the code (e.g., make benchmarks debug=1 ). Using this option, the code will run much slower, so this option is not recommended unless necessary.","title":"3. Compile the code."},{"location":"getting-started/#4-run-the-model","text":"Once an executable has been created, you can run the model. This can be achieved via the included Python job submission script runylmo . The following steps are carried out via the script: The output directory is created. The executable is copied to the output directory The relevant parameter files are copied to the output directory. Links to the input data paths ( input and ice_data ) are created in the output directory. Note that many simulations, such as benchmark experiments, do not depend on these external data sources, but the links are made anyway. The executable is run from the output directory, either as a background process or it is submitted to the queue via sbatch (the SLURM workload manager). To run a benchmark simulation, for example, use the following command: ./runylmo -r -e benchmarks -o output/test -n par/yelmo_EISMINT.nml where the option -r implies that the model should be run as a background process. If this is omitted, then the output directory will be populated, but no executable will be run, while -s instead will submit the simulation to cluster queue system instead of running in the background. The option -e lets you specify the executable. For some standard cases, shortcuts have been created: benchmarks = libyelmo/bin/yelmo_benchmarks.x mismip = libyelmo/bin/yemo_mismip.x initmip = libyelmo/bin/yelmo_initmip.x The last two mandatory arguments -o OUTDIR and -n PAR_PATH are the output/run directory and the parameter file to be used for this simulation, respectively. In the case of the above simulation, the output directory is defined as output/test , where all model parameters (loaded from the file par/yelmo_EISMINT.nml ) and model output can be found. It is also possible to modify parameters inline via the option -p KEY=VAL [KEY=VAL ...] . The parameter should be specified with its namelist group and its name. E.g., to change the resolution of the EISMINT benchmark experiment to 10km, use: ./runylmo -r -e benchmarks -o output/test -n par/yelmo_EISMINT.nml -p ctrl.dx=10 See runylmo -h for more details on the run script.","title":"4. Run the model."},{"location":"getting-started/#test-cases","text":"The published model description includes several test simulations for validation of the model's performance. The following section describes how to perform these tests using the same model version documented in the article. From this point, it is assumed that the user has already configured the model for their system (see https://palma-ice.github.io/yelmo-docs) and is ready to compile the mode.","title":"Test cases"},{"location":"getting-started/#1-eismint1-moving-margin-experiment","text":"To perform the moving margin experiment, compile the benchmarks executable and call it with the EISMINT parameter file: make benchmarks ./runylmo -r -e benchmarks -o output/eismint-moving -n par-gmd/yelmo_EISMINT_moving.nml","title":"1. EISMINT1 moving margin experiment"},{"location":"getting-started/#2-eismint2-expa","text":"To perform Experiment A from the EISMINT2 benchmarks, compile the benchmarks executable and call it with the EXPA parameter file: make benchmarks ./runylmo -r -e benchmarks -o output/eismint-expa -n par-gmd/yelmo_EISMINT_expa.nml","title":"2. EISMINT2 EXPA"},{"location":"getting-started/#3-eismint2-expf","text":"To perform Experiment F from the EISMINT2 benchmarks, compile the benchmarks executable and call it with the EXPF parameter file: make benchmarks ./runylmo -r -e benchmarks -o output/eismint-expf -n par-gmd/yelmo_EISMINT_expf.nml","title":"3. EISMINT2 EXPF"},{"location":"getting-started/#4-mismip-rf","text":"To perform the MISMIP rate factor experiment, compile the mismip executable and call it with the MISMIP parameter file the three parameter permutations of interest (default, subgrid and subgrid+gl-scaling): make mismip ./runylmo -r -e mismip -o output/mismip-rf-0 -n par-gmd/yelmo_MISMIP3D.nml -p ydyn.beta_gl_stag=0 ydyn.beta_gl_scale=0 ./runylmo -r -e mismip -o output/mismip-rf-1 -n par-gmd/yelmo_MISMIP3D.nml -p ydyn.beta_gl_stag=3 ydyn.beta_gl_scale=0 ./runylmo -r -e mismip -o output/mismip-rf-2 -n par-gmd/yelmo_MISMIP3D.nml -p ydyn.beta_gl_stag=3 ydyn.beta_gl_scale=2 To additionally change the resolution of the simulations change the parameter mismip.dx , e.g. for the default simulation with 10km resolution , call: ./runylmo -r -e mismip -o output/mismip-rf-0-10km -n par-gmd/yelmo_MISMIP3D.nml -p ydyn.beta_gl_stag=0 ydyn.beta_gl_scale=0 mismip.dx=10","title":"4. MISMIP RF"},{"location":"getting-started/#5-age-profile-experiments","text":"To perform the age profile experiments, compile the Fortran program tests/test_icetemp.f90 and run it: make icetemp ./libyelmo/bin/test_icetemp.x To perform the different permutations, it is necessary to recompile for single or double precision after changing the precision parameter prec in the file src/yelmo_defs.f90 . The number of vertical grid points can be specified in the main program file, as well as the output filename.","title":"5. Age profile experiments"},{"location":"getting-started/#6-antarctica-present-day-and-glacial-simulations","text":"To perform the Antarctica simulations as presented in the paper, it is necessary to compile the initmip executable and run with the present-day (pd) and glacial (lgm) parameter values: make initmip ./runylmo -r -e initmip -o output/ant-pd -n par-gmd/yelmo_Antarctica.nml -p ctrl.clim_nm=\"clim_pd\" ./runylmo -r -e initmip -o output/ant-lgm -n par-gmd/yelmo_Antarctica.nml -p ctrl.clim_nm=\"clim_lgm\"","title":"6. Antarctica present-day and glacial simulations"},{"location":"notes/","text":"Notes master to main Following updated conventions, the default branch is now called main and the branch master has been deleted. To update a working copy locally that already contains a master branch and therefore points to it as the default branch, the following steps should be applied: Get the branch main . Delete the local branch master . Make sure your local repository sees main as the default branch. # Get all branch information from the origin (github): git fetch --all # Get onto the new default branch: git checkout main # Delete the branch master: git branch -d master # Clean up any branches that no longer exist at origin: git fetch --prune origin # Set the local 'head' to whatever is specified at the origin (which will be main): git remote set-head origin -a Done! Now your local copy should work like normal, with main instead of master . Thermodynamics equations Ice column Prognostic equation: \\frac{\\partial T}{\\partial t} = \\frac{k}{\\rho c} \\frac{\\partial^2 T}{\\partial z^2} - u \\frac{\\partial T}{\\partial x} - v \\frac{\\partial T}{\\partial y} - w \\frac{\\partial T}{\\partial z} + \\frac{\\Phi}{\\rho c} Ice surface boundary condition: T(z=z_{\\rm srf}) = {\\rm min}(T_{\\rm 2m},T_0) Ice base (temperate) boundary condition: T(z=z_{\\rm bed}) = T_{\\rm pmp} Ice base (frozen) boundary condition: k \\frac{\\partial T}{\\partial z} = k_r \\frac{\\partial T_r}{\\partial z} Note, the following internal Yelmo variables are defined for convenience: Q_{\\rm ice,b} = -k \\frac{\\partial T}{\\partial z}; \\quad Q_{\\rm rock} = -k_r \\frac{\\partial T_r}{\\partial z} Bedrock column Prognostic equation: \\frac{\\partial T_r}{\\partial t} = \\frac{k_r}{\\rho_r c_r} \\frac{\\partial^2 T_r}{\\partial z^2} Bedrock surface boundary condition: T_r(z=z_{\\rm bed}) = T(z=z_{\\rm bed}) Bedrock base boundary condition: \\frac{\\partial T_r}{\\partial z} = -\\frac{Q_{\\rm geo}}{k_r} Equilibrium bedrock In this case, the bedrock temperature profile is prescribed to the equilibrium linear temperature profile. The slope follows: \\frac{\\partial T_r}{\\partial z} = -\\frac{Q_{\\rm geo}}{k_r} and the bedrock surface temperature is given by the ice temperature at its base: T_r(z=z_{\\rm bed}) = T(z=z_{\\rm bed}) Active bedrock Yelmo calculates the temperature in the lithosphere along with the ice temperature. This can be achieved by assuming equilibrium conditions in the bedrock, i.e., that the temperature profile in the bedrock is always linear with T_lith_s = T_ice_b and the slope equal to dT/dz = -Q_geo / k_lith . Or, the temperature equation can be solved in the lithosphere together with the temperature in the ice column. The parameter block ytherm_lith controls how the lithosphere is calculated with ytherm_lith.method=['equil','active'] deciding the two cases above. Density of the upper lithosphere Heat capacity of the upper lithosphere In both SICOPOLIS and GRISLI, a value of cp = 1000.0 [J kg-1 K-1] is used (referenced in Rogozhina et al., 2012; Greve, 2005; Greve, 1997). This value is adopted in Yelmo as well. cp = 1000.0 ! [J kg-1 K-1] Heat conductivity of the upper lithosphere Note, Yelmo expects input parameter values in units of [J a-1 m-1 K-1] , while much literature uses [W m-1 K-1] . Given the number of seconds in a year sec_year = 31536000.0 , kt [W m-1 K-1] * sec_year = kt [J a-1 m-1 K-1] . Rogozhina et al. (2012) use kt = 2 [W m-1 K-1] for Greenland: kt = 6.3e7 ! [J a-1 m-1 K-1] This value is supported by L\u00f6sing et al. (2020), who perform a Bayesian inversion for GHF in Antarctica. Assuming exponentially decreasing heat production with depth, lower values of kt are supported (see Fig. 7b). In a study on the global thermal characteristics of the lithosphere, Cammarano and Guerri (2017) adopt an upper crust thermal conductivity of kt = 2.5 [W m-1 K-1] . To do: This study is also potentially relevant: https://link.springer.com/article/10.1186/s40517-020-0159-y . They show ranges of on the order of kt = 2-3 [W m-1 K-1] for the Canadian shield. The above value of kt = 2 [W m-1 K-1] = 6.3e7 [J a-1 m-1 K-1] is adopted as the default thermal conductivity of the upper crust in Yelmo. For historical context, see other estimates below. From Greve (1997) and Greve (2005): kt = 9.46e7 ! [J a-1 m-1 K-1] which is equivalent to kt = 3 [W m-1 K-1] . The source of this value is not known. From GRISLI: kt = 1.04e8 ! [J a-1 m-1 K-1] which is equivalent to kt = 3.3 [W m-1 K-1] . The source of this value is not known. How to read yelmo_check_kill output The subroutine yelmo_check_kill is used to see if any instability is arising in the model. If so, then a restart file is written at that moment (the earlier in the instability, the better), and the model is stopped with diagnostic output to the log file. Note that pc_eps is the parameter that defines our target error tolerance in the time stepping of ice thickness evolution. At each time step, the diagnosed model error pc_eta is compared with pc_eps . If pc_eta >> pc_eps , this is interpreted as instability and the model is stopped.","title":"Notes"},{"location":"notes/#notes","text":"","title":"Notes"},{"location":"notes/#master-to-main","text":"Following updated conventions, the default branch is now called main and the branch master has been deleted. To update a working copy locally that already contains a master branch and therefore points to it as the default branch, the following steps should be applied: Get the branch main . Delete the local branch master . Make sure your local repository sees main as the default branch. # Get all branch information from the origin (github): git fetch --all # Get onto the new default branch: git checkout main # Delete the branch master: git branch -d master # Clean up any branches that no longer exist at origin: git fetch --prune origin # Set the local 'head' to whatever is specified at the origin (which will be main): git remote set-head origin -a Done! Now your local copy should work like normal, with main instead of master .","title":"master to main"},{"location":"notes/#thermodynamics-equations","text":"","title":"Thermodynamics equations"},{"location":"notes/#ice-column","text":"Prognostic equation: \\frac{\\partial T}{\\partial t} = \\frac{k}{\\rho c} \\frac{\\partial^2 T}{\\partial z^2} - u \\frac{\\partial T}{\\partial x} - v \\frac{\\partial T}{\\partial y} - w \\frac{\\partial T}{\\partial z} + \\frac{\\Phi}{\\rho c} Ice surface boundary condition: T(z=z_{\\rm srf}) = {\\rm min}(T_{\\rm 2m},T_0) Ice base (temperate) boundary condition: T(z=z_{\\rm bed}) = T_{\\rm pmp} Ice base (frozen) boundary condition: k \\frac{\\partial T}{\\partial z} = k_r \\frac{\\partial T_r}{\\partial z} Note, the following internal Yelmo variables are defined for convenience: Q_{\\rm ice,b} = -k \\frac{\\partial T}{\\partial z}; \\quad Q_{\\rm rock} = -k_r \\frac{\\partial T_r}{\\partial z}","title":"Ice column"},{"location":"notes/#bedrock-column","text":"Prognostic equation: \\frac{\\partial T_r}{\\partial t} = \\frac{k_r}{\\rho_r c_r} \\frac{\\partial^2 T_r}{\\partial z^2} Bedrock surface boundary condition: T_r(z=z_{\\rm bed}) = T(z=z_{\\rm bed}) Bedrock base boundary condition: \\frac{\\partial T_r}{\\partial z} = -\\frac{Q_{\\rm geo}}{k_r}","title":"Bedrock column"},{"location":"notes/#equilibrium-bedrock","text":"In this case, the bedrock temperature profile is prescribed to the equilibrium linear temperature profile. The slope follows: \\frac{\\partial T_r}{\\partial z} = -\\frac{Q_{\\rm geo}}{k_r} and the bedrock surface temperature is given by the ice temperature at its base: T_r(z=z_{\\rm bed}) = T(z=z_{\\rm bed})","title":"Equilibrium bedrock"},{"location":"notes/#active-bedrock","text":"Yelmo calculates the temperature in the lithosphere along with the ice temperature. This can be achieved by assuming equilibrium conditions in the bedrock, i.e., that the temperature profile in the bedrock is always linear with T_lith_s = T_ice_b and the slope equal to dT/dz = -Q_geo / k_lith . Or, the temperature equation can be solved in the lithosphere together with the temperature in the ice column. The parameter block ytherm_lith controls how the lithosphere is calculated with ytherm_lith.method=['equil','active'] deciding the two cases above.","title":"Active bedrock"},{"location":"notes/#density-of-the-upper-lithosphere","text":"","title":"Density of the upper lithosphere"},{"location":"notes/#heat-capacity-of-the-upper-lithosphere","text":"In both SICOPOLIS and GRISLI, a value of cp = 1000.0 [J kg-1 K-1] is used (referenced in Rogozhina et al., 2012; Greve, 2005; Greve, 1997). This value is adopted in Yelmo as well. cp = 1000.0 ! [J kg-1 K-1]","title":"Heat capacity of the upper lithosphere"},{"location":"notes/#heat-conductivity-of-the-upper-lithosphere","text":"Note, Yelmo expects input parameter values in units of [J a-1 m-1 K-1] , while much literature uses [W m-1 K-1] . Given the number of seconds in a year sec_year = 31536000.0 , kt [W m-1 K-1] * sec_year = kt [J a-1 m-1 K-1] . Rogozhina et al. (2012) use kt = 2 [W m-1 K-1] for Greenland: kt = 6.3e7 ! [J a-1 m-1 K-1] This value is supported by L\u00f6sing et al. (2020), who perform a Bayesian inversion for GHF in Antarctica. Assuming exponentially decreasing heat production with depth, lower values of kt are supported (see Fig. 7b). In a study on the global thermal characteristics of the lithosphere, Cammarano and Guerri (2017) adopt an upper crust thermal conductivity of kt = 2.5 [W m-1 K-1] . To do: This study is also potentially relevant: https://link.springer.com/article/10.1186/s40517-020-0159-y . They show ranges of on the order of kt = 2-3 [W m-1 K-1] for the Canadian shield. The above value of kt = 2 [W m-1 K-1] = 6.3e7 [J a-1 m-1 K-1] is adopted as the default thermal conductivity of the upper crust in Yelmo. For historical context, see other estimates below. From Greve (1997) and Greve (2005): kt = 9.46e7 ! [J a-1 m-1 K-1] which is equivalent to kt = 3 [W m-1 K-1] . The source of this value is not known. From GRISLI: kt = 1.04e8 ! [J a-1 m-1 K-1] which is equivalent to kt = 3.3 [W m-1 K-1] . The source of this value is not known.","title":"Heat conductivity of the upper lithosphere"},{"location":"notes/#how-to-read-yelmo_check_kill-output","text":"The subroutine yelmo_check_kill is used to see if any instability is arising in the model. If so, then a restart file is written at that moment (the earlier in the instability, the better), and the model is stopped with diagnostic output to the log file. Note that pc_eps is the parameter that defines our target error tolerance in the time stepping of ice thickness evolution. At each time step, the diagnosed model error pc_eta is compared with pc_eps . If pc_eta >> pc_eps , this is interpreted as instability and the model is stopped.","title":"How to read yelmo_check_kill output"},{"location":"optimization/","text":"Basal friction optimization A simple optimization program has developed that attempts to optimize the basal friction field applied in Yelmo so that the errors between simulated and observed ice thickness are minimized. Program: tests/yelmo_opt.f90 To compile: make opt To run: ./runylmo -s -e opt -o output/test -n par/yelmo_Antarctica_opt.nml The program consists of the following steps: 1. Spin-up a steady-state ice sheet with constant forcing and fixed topography. For this step, the restart parameter should be set to yelmo.restart='none' , to ensure that the spin-up is performed with the current parameters. Currently, the program is hard-coded to spin-up the ice sheet for 20 kyr using SIA only, followed by another 10 kyr using the solver of choice, as seen in the following lines of code: call yelmo_update_equil_external(yelmo1,hyd1,cf_ref,time_init,time_tot=20e3,topo_fixed=.TRUE.,dt=5.0,ssa_vel_max=0.0) call yelmo_update_equil_external(yelmo1,hyd1,cf_ref,time_init,time_tot=10e3, topo_fixed=.TRUE.,dt=1.0,ssa_vel_max=5000.0) Note that this spin-up is obtained with a fixed topography set to the present-day observed fields ( H_ice , z_bed ). After the spin-up finishes, a restart file is written in the output directory with the name yelmo_restart.nc . The simulation will terminate at this point. 2. Optimization The restart file from Step 1 should be saved somewhere convenient for the model (like in the input folder). Then the restart parameter should be set to that location yelmo.restart='PATH_TO_RESTART.nc' . This will ensure that the spin-up step is skipped, and instead the program will start directly with the optimization iterations. The optimization method follows Pollard and DeConto (2012), in that the basal friction coefficient is scaled as a function of the error in elevation. Here we do not modify beta directly, however, we assume that beta = cf_ref * lambda_bed * N_eff * f(u) . lambda_bed , N_eff and f(u) are all controlled by parameter choices in the .nml file like normal. Thus we are left with a unitless field cf_ref , which for any given friction law varies within the range of about [0:1]. When cf_ref=1.0 , sliding will diminish to near zero, and cf_ref~0.0 (near, but not zero) will give fast sliding. This gives a convenient range for optimization. Parameters that control the total run time are hard coded: qmax : number of total iterations to run, where qmax-1 is the number of optimization steps, during which cf_ref is updated, and the last step is a steady-state run with cf_ref held constant. time_iter : time to run the model for each iteration before updating cf_ref . time_steady : Time to run the model to steady state with cf_ref held constant (last iteration step). So, the program runs for, e.g., time_iter=500 years with a given initial field of cf_ref (with C_bed and beta updating every time step to follow changes in u/v and N_eff ). At the end of time_iter , the error in ice thickness is determined and used to update cf_ref via the function update_cf_ref_thickness_simple . The model is again run for time_iter years and the process is repeated. Two important parameters control the optimization process: tau and H_scale . The optimization works best when the ice shelves are relaxed to the reference (observed) ice thickness in the beginning of the simulation, and then gradually allowed to freely evolve. tau is the time scale of relaxation, which is applied in Yelmo as yelmo1%tpo%par%topo_rel_tau . A lower value of tau means that the ice shelves are more tightly held to the observed thickness. Likewise, H_scale controls the scaling of the ice thickness error, which determines how to modify cf_ref at each iteration. A higher value of H_scale means that changes to cf_ref will be applied more slowly. These parameters are designed to change over time with the simulation. tau is set to rel_tau1 from the start of the simulation until rel_time1 . Between rel_time1 and rel_time2 , tau is linearly scaled from the value of rel_tau1 to rel_tau2 . Or, if rel_q > 1 , then the scaling is non-linear with an exponent of rel_q (this helps maintain small values of tau longer which seems to help keep errors low). Once rel_time2 is reached, relaxation in the model is disabled, and the ice shelves are allowed to freely evolve. Analogously, H_scale is modified the same way: it is constant at the value of scale_H1 until scale_time1 , linearly scaled between scale_time1 and scale_time2 , and then constant thereafter at the value of scale_H2 . Increasing the value of H_scale over time helps to avoid oscillations in the optimization procedure as cf_ref approaches the best fit. Finally, after qmax-1 iterations or time=(qmax-1)*time_iter , cf_ref is held constant, and the simulation runs for time_steady years to equilibrate the model with the current conditions. This step minimizes drift in the final result and confirms that the optimized cf_ref field works well.","title":"Basal friction optimization"},{"location":"optimization/#basal-friction-optimization","text":"A simple optimization program has developed that attempts to optimize the basal friction field applied in Yelmo so that the errors between simulated and observed ice thickness are minimized. Program: tests/yelmo_opt.f90 To compile: make opt To run: ./runylmo -s -e opt -o output/test -n par/yelmo_Antarctica_opt.nml The program consists of the following steps:","title":"Basal friction optimization"},{"location":"optimization/#1-spin-up-a-steady-state-ice-sheet-with-constant-forcing-and-fixed-topography","text":"For this step, the restart parameter should be set to yelmo.restart='none' , to ensure that the spin-up is performed with the current parameters. Currently, the program is hard-coded to spin-up the ice sheet for 20 kyr using SIA only, followed by another 10 kyr using the solver of choice, as seen in the following lines of code: call yelmo_update_equil_external(yelmo1,hyd1,cf_ref,time_init,time_tot=20e3,topo_fixed=.TRUE.,dt=5.0,ssa_vel_max=0.0) call yelmo_update_equil_external(yelmo1,hyd1,cf_ref,time_init,time_tot=10e3, topo_fixed=.TRUE.,dt=1.0,ssa_vel_max=5000.0) Note that this spin-up is obtained with a fixed topography set to the present-day observed fields ( H_ice , z_bed ). After the spin-up finishes, a restart file is written in the output directory with the name yelmo_restart.nc . The simulation will terminate at this point.","title":"1. Spin-up a steady-state ice sheet with constant forcing and fixed topography."},{"location":"optimization/#2-optimization","text":"The restart file from Step 1 should be saved somewhere convenient for the model (like in the input folder). Then the restart parameter should be set to that location yelmo.restart='PATH_TO_RESTART.nc' . This will ensure that the spin-up step is skipped, and instead the program will start directly with the optimization iterations. The optimization method follows Pollard and DeConto (2012), in that the basal friction coefficient is scaled as a function of the error in elevation. Here we do not modify beta directly, however, we assume that beta = cf_ref * lambda_bed * N_eff * f(u) . lambda_bed , N_eff and f(u) are all controlled by parameter choices in the .nml file like normal. Thus we are left with a unitless field cf_ref , which for any given friction law varies within the range of about [0:1]. When cf_ref=1.0 , sliding will diminish to near zero, and cf_ref~0.0 (near, but not zero) will give fast sliding. This gives a convenient range for optimization. Parameters that control the total run time are hard coded: qmax : number of total iterations to run, where qmax-1 is the number of optimization steps, during which cf_ref is updated, and the last step is a steady-state run with cf_ref held constant. time_iter : time to run the model for each iteration before updating cf_ref . time_steady : Time to run the model to steady state with cf_ref held constant (last iteration step). So, the program runs for, e.g., time_iter=500 years with a given initial field of cf_ref (with C_bed and beta updating every time step to follow changes in u/v and N_eff ). At the end of time_iter , the error in ice thickness is determined and used to update cf_ref via the function update_cf_ref_thickness_simple . The model is again run for time_iter years and the process is repeated. Two important parameters control the optimization process: tau and H_scale . The optimization works best when the ice shelves are relaxed to the reference (observed) ice thickness in the beginning of the simulation, and then gradually allowed to freely evolve. tau is the time scale of relaxation, which is applied in Yelmo as yelmo1%tpo%par%topo_rel_tau . A lower value of tau means that the ice shelves are more tightly held to the observed thickness. Likewise, H_scale controls the scaling of the ice thickness error, which determines how to modify cf_ref at each iteration. A higher value of H_scale means that changes to cf_ref will be applied more slowly. These parameters are designed to change over time with the simulation. tau is set to rel_tau1 from the start of the simulation until rel_time1 . Between rel_time1 and rel_time2 , tau is linearly scaled from the value of rel_tau1 to rel_tau2 . Or, if rel_q > 1 , then the scaling is non-linear with an exponent of rel_q (this helps maintain small values of tau longer which seems to help keep errors low). Once rel_time2 is reached, relaxation in the model is disabled, and the ice shelves are allowed to freely evolve. Analogously, H_scale is modified the same way: it is constant at the value of scale_H1 until scale_time1 , linearly scaled between scale_time1 and scale_time2 , and then constant thereafter at the value of scale_H2 . Increasing the value of H_scale over time helps to avoid oscillations in the optimization procedure as cf_ref approaches the best fit. Finally, after qmax-1 iterations or time=(qmax-1)*time_iter , cf_ref is held constant, and the simulation runs for time_steady years to equilibrate the model with the current conditions. This step minimizes drift in the final result and confirms that the optimized cf_ref field works well.","title":"2. Optimization"},{"location":"parameters/","text":"Parameters Here important parameter choices pertinent to running Yelmo will be documented. Each section will outline a specific parameter or set of related parameters. The author of each section and the date last updated will apear in the heading, to maintain traceability in the documentation (since code usually changes over time). To do","title":"Parameters"},{"location":"parameters/#parameters","text":"Here important parameter choices pertinent to running Yelmo will be documented. Each section will outline a specific parameter or set of related parameters. The author of each section and the date last updated will apear in the heading, to maintain traceability in the documentation (since code usually changes over time).","title":"Parameters"},{"location":"parameters/#to-do","text":"","title":"To do"},{"location":"snapclim/","text":"Snapshot climate (snapclim) The snapclim module is designed to determine climatic forcing, i.e., monthly temperature and precipitation, for a given point in time. This can be acheived by applying a temperature anomaly, or by interpolating snapshots of climate states available for different times. The \"hybrid\" method. This is my preferred method and is set up to be rather flexible, and I think is a good place to start for these simulations. It is comprised of an annual mean temperature anomaly time series from 300 kyr ago to today obtained from several spliced paleo reconstructions plus a monthly seasonal cycle over the 300 kyr obtained from a climber2 paleo run. So with the monthly values and the annual mean, you can get monthly temp anomalies over 300 kyr. There are more details in the attached manuscript that was never yet submitted... To activate this method, in the parameter file, set the following parameters in the group \"snapclim\": atm_type = \"hybrid\" ocn_type = \"hybrid\" Then in the group \"snapclim_hybrid\", you can specify: f_eem = 0.4 # Controls the maximum temp anomaly during the Eemian f_glac = 1.0 # Controls the minimum temp anomaly during the glacial period f_hol = 0.5 # Controls the maximum temp anomaly during the Holocene f_seas = 1.0 # Controls the magnitude of the seasonal cycle f_to = 0.2 # Defines the oceanic temperature anomaly relative # to the annual mean atmospheric temp anomaly","title":"Snapshot climate (snapclim)"},{"location":"snapclim/#snapshot-climate-snapclim","text":"The snapclim module is designed to determine climatic forcing, i.e., monthly temperature and precipitation, for a given point in time. This can be acheived by applying a temperature anomaly, or by interpolating snapshots of climate states available for different times.","title":"Snapshot climate (snapclim)"},{"location":"snapclim/#the-hybrid-method","text":"This is my preferred method and is set up to be rather flexible, and I think is a good place to start for these simulations. It is comprised of an annual mean temperature anomaly time series from 300 kyr ago to today obtained from several spliced paleo reconstructions plus a monthly seasonal cycle over the 300 kyr obtained from a climber2 paleo run. So with the monthly values and the annual mean, you can get monthly temp anomalies over 300 kyr. There are more details in the attached manuscript that was never yet submitted... To activate this method, in the parameter file, set the following parameters in the group \"snapclim\": atm_type = \"hybrid\" ocn_type = \"hybrid\" Then in the group \"snapclim_hybrid\", you can specify: f_eem = 0.4 # Controls the maximum temp anomaly during the Eemian f_glac = 1.0 # Controls the minimum temp anomaly during the glacial period f_hol = 0.5 # Controls the maximum temp anomaly during the Holocene f_seas = 1.0 # Controls the magnitude of the seasonal cycle f_to = 0.2 # Defines the oceanic temperature anomaly relative # to the annual mean atmospheric temp anomaly","title":"The \"hybrid\" method."}]}